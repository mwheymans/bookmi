<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 5 Data analysis after Multiple Imputation | Applied Missing data analysis with SPSS and R(Studio)</title>
  <meta name="description" content="Chapter 5 Data analysis after Multiple Imputation | Applied Missing data analysis with SPSS and R(Studio)>
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 5 Data analysis after Multiple Imputation | Applied Missing data analysis with SPSS and R(Studio) />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Data analysis after Multiple Imputation | Applied Missing data analysis with SPSS and R(Studio) />
  
  
  

<meta name="author" content="Martijn Heymans and Iris Eekhout">


<meta name="date" content="2019-01-05">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="part-iv-data-analysis-after-multiple-imputation.html">
<link rel="next" href="more-topics-on-multiple-imputation-and-regression-modelling.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied Missing Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Foreword</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#software"><i class="fa fa-check"></i><b>0.1</b> Software</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#notation-in-this-book"><i class="fa fa-check"></i><b>0.2</b> Notation in this book</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#acknowledgement"><i class="fa fa-check"></i><b>0.3</b> Acknowledgement</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-i-software.html"><a href="part-i-software.html"><i class="fa fa-check"></i>Part I - Software</a></li>
<li class="chapter" data-level="1" data-path="software-applications.html"><a href="software-applications.html"><i class="fa fa-check"></i><b>1</b> Software applications</a><ul>
<li class="chapter" data-level="1.1" data-path="software-applications.html"><a href="software-applications.html#spss"><i class="fa fa-check"></i><b>1.1</b> SPSS</a><ul>
<li class="chapter" data-level="1.1.1" data-path="software-applications.html"><a href="software-applications.html#data-and-variable-view-windows"><i class="fa fa-check"></i><b>1.1.1</b> Data and Variable View windows</a></li>
<li class="chapter" data-level="1.1.2" data-path="software-applications.html"><a href="software-applications.html#analyzing-data-in-spss"><i class="fa fa-check"></i><b>1.1.2</b> Analyzing data in SPSS</a></li>
<li class="chapter" data-level="1.1.3" data-path="software-applications.html"><a href="software-applications.html#the-output-window-in-spss"><i class="fa fa-check"></i><b>1.1.3</b> The Output window in SPSS</a></li>
<li class="chapter" data-level="1.1.4" data-path="software-applications.html"><a href="software-applications.html#the-syntax-editor-in-spss"><i class="fa fa-check"></i><b>1.1.4</b> The Syntax Editor in SPSS</a></li>
<li class="chapter" data-level="1.1.5" data-path="software-applications.html"><a href="software-applications.html#reading-and-saving-data-in-spss"><i class="fa fa-check"></i><b>1.1.5</b> Reading and saving data in SPSS</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="software-applications.html"><a href="software-applications.html#r-and-rstudio"><i class="fa fa-check"></i><b>1.2</b> R and RStudio</a><ul>
<li class="chapter" data-level="1.2.1" data-path="software-applications.html"><a href="software-applications.html#the-role-of-the-console-window"><i class="fa fa-check"></i><b>1.2.1</b> The role of the Console Window</a></li>
<li class="chapter" data-level="1.2.2" data-path="software-applications.html"><a href="software-applications.html#r-assignments-and-objects"><i class="fa fa-check"></i><b>1.2.2</b> R assignments and objects</a></li>
<li class="chapter" data-level="1.2.3" data-path="software-applications.html"><a href="software-applications.html#vectors-matrices-lists-and-data-frames"><i class="fa fa-check"></i><b>1.2.3</b> Vectors, matrices, lists and data frames</a></li>
<li class="chapter" data-level="1.2.4" data-path="software-applications.html"><a href="software-applications.html#indexing-vectors-matrices-lists-and-data-frames"><i class="fa fa-check"></i><b>1.2.4</b> Indexing Vectors, Matrices, Lists and Data frames</a></li>
<li class="chapter" data-level="1.2.5" data-path="software-applications.html"><a href="software-applications.html#vectorized-calculation"><i class="fa fa-check"></i><b>1.2.5</b> Vectorized Calculation</a></li>
<li class="chapter" data-level="1.2.6" data-path="software-applications.html"><a href="software-applications.html#r-functions"><i class="fa fa-check"></i><b>1.2.6</b> R Functions</a></li>
<li class="chapter" data-level="1.2.7" data-path="software-applications.html"><a href="software-applications.html#the-help-function"><i class="fa fa-check"></i><b>1.2.7</b> The Help function</a></li>
<li class="chapter" data-level="1.2.8" data-path="software-applications.html"><a href="software-applications.html#working-with-script-files"><i class="fa fa-check"></i><b>1.2.8</b> Working with script files</a></li>
<li class="chapter" data-level="1.2.9" data-path="software-applications.html"><a href="software-applications.html#creating-a-working-directory"><i class="fa fa-check"></i><b>1.2.9</b> Creating a working directory</a></li>
<li class="chapter" data-level="1.2.10" data-path="software-applications.html"><a href="software-applications.html#reading-in-spss-data-in-rstudio"><i class="fa fa-check"></i><b>1.2.10</b> Reading in SPSS data in RStudio</a></li>
<li class="chapter" data-level="1.2.11" data-path="software-applications.html"><a href="software-applications.html#saving-and-reading-r-data-in-rstudio"><i class="fa fa-check"></i><b>1.2.11</b> Saving and Reading R data in RStudio</a></li>
<li class="chapter" data-level="1.2.12" data-path="software-applications.html"><a href="software-applications.html#reading-in-rstudio-data-into-spss"><i class="fa fa-check"></i><b>1.2.12</b> Reading in (R)Studio data into SPSS</a></li>
<li class="chapter" data-level="1.2.13" data-path="software-applications.html"><a href="software-applications.html#installing-r-packages"><i class="fa fa-check"></i><b>1.2.13</b> Installing R Packages</a></li>
<li class="chapter" data-level="1.2.14" data-path="software-applications.html"><a href="software-applications.html#loading-r-packages"><i class="fa fa-check"></i><b>1.2.14</b> Loading R Packages</a></li>
<li class="chapter" data-level="1.2.15" data-path="software-applications.html"><a href="software-applications.html#updating-r-packages"><i class="fa fa-check"></i><b>1.2.15</b> Updating R Packages</a></li>
<li class="chapter" data-level="1.2.16" data-path="software-applications.html"><a href="software-applications.html#useful-missing-data-packages-and-links"><i class="fa fa-check"></i><b>1.2.16</b> Useful Missing data Packages and links</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-ii-basic-missing-data-handling.html"><a href="part-ii-basic-missing-data-handling.html"><i class="fa fa-check"></i>Part II – Basic Missing Data Handling</a></li>
<li class="chapter" data-level="2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html"><i class="fa fa-check"></i><b>2</b> Missing Data Evaluation</a><ul>
<li class="chapter" data-level="2.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#definition-of-missing-data"><i class="fa fa-check"></i><b>2.1</b> Definition of Missing Data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#defining-missing-data-in-spss"><i class="fa fa-check"></i><b>2.1.1</b> Defining Missing Data in SPSS</a></li>
<li class="chapter" data-level="2.1.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-in-r"><i class="fa fa-check"></i><b>2.1.2</b> Missing data in R</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-patterns"><i class="fa fa-check"></i><b>2.2</b> Missing data Patterns</a><ul>
<li class="chapter" data-level="2.2.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-patterns-in-spss"><i class="fa fa-check"></i><b>2.2.1</b> Missing data patterns in SPSS</a></li>
<li class="chapter" data-level="2.2.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-patterns-in-r"><i class="fa fa-check"></i><b>2.2.2</b> Missing data patterns in R</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-mechanisms"><i class="fa fa-check"></i><b>2.3</b> 2.3 Missing data Mechanisms</a><ul>
<li class="chapter" data-level="2.3.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-completely-at-random"><i class="fa fa-check"></i><b>2.3.1</b> 2.3.1 Missing Completely At Random</a></li>
<li class="chapter" data-level="2.3.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-at-random"><i class="fa fa-check"></i><b>2.3.2</b> Missing At Random</a></li>
<li class="chapter" data-level="2.3.3" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-not-at-random"><i class="fa fa-check"></i><b>2.3.3</b> Missing Not At Random</a></li>
<li class="chapter" data-level="2.3.4" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#the-missing-data-indicator"><i class="fa fa-check"></i><b>2.3.4</b> The Missing Data Indicator</a></li>
<li class="chapter" data-level="2.3.5" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#the-role-of-auxiliary-variables"><i class="fa fa-check"></i><b>2.3.5</b> The Role of Auxiliary Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-evaluation-1"><i class="fa fa-check"></i><b>2.4</b> Missing Data evaluation</a><ul>
<li class="chapter" data-level="2.4.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-evaluation-in-spss"><i class="fa fa-check"></i><b>2.4.1</b> Missing data Evaluation in SPSS</a></li>
<li class="chapter" data-level="2.4.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-evaluation-in-r"><i class="fa fa-check"></i><b>2.4.2</b> Missing data Evaluation in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html"><i class="fa fa-check"></i><b>3</b> Single Missing data imputations</a><ul>
<li class="chapter" data-level="3.1" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#complete-cases-analysis"><i class="fa fa-check"></i><b>3.1</b> Complete cases analysis</a></li>
<li class="chapter" data-level="3.2" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#mean-imputation"><i class="fa fa-check"></i><b>3.2</b> Mean Imputation</a><ul>
<li class="chapter" data-level="3.2.1" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#mean-imputation-in-spss"><i class="fa fa-check"></i><b>3.2.1</b> Mean imputation in SPSS</a></li>
<li class="chapter" data-level="3.2.2" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#mean-imputation-in-r"><i class="fa fa-check"></i><b>3.2.2</b> Mean imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#regression-imputation"><i class="fa fa-check"></i><b>3.3</b> Regression imputation</a><ul>
<li class="chapter" data-level="3.3.1" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#regression-imputation-in-spss"><i class="fa fa-check"></i><b>3.3.1</b> Regression imputation in SPSS</a></li>
<li class="chapter" data-level="3.3.2" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#regression-imputation-in-r"><i class="fa fa-check"></i><b>3.3.2</b> Regression imputation in R</a></li>
<li class="chapter" data-level="3.3.3" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#stochastic-regression-imputation"><i class="fa fa-check"></i><b>3.3.3</b> Stochastic regression imputation</a></li>
<li class="chapter" data-level="3.3.4" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#stochastic-regression-imputation-in-r"><i class="fa fa-check"></i><b>3.3.4</b> Stochastic regression imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#bayesian-stochastic-regression-imputation"><i class="fa fa-check"></i><b>3.4</b> Bayesian Stochastic regression imputation</a><ul>
<li class="chapter" data-level="3.4.1" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#bayesian-stochastic-regression-imputation-in-spss"><i class="fa fa-check"></i><b>3.4.1</b> Bayesian Stochastic regression imputation in SPSS</a></li>
<li class="chapter" data-level="3.4.2" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#bayesian-stochastic-regression-imputation-in-r"><i class="fa fa-check"></i><b>3.4.2</b> Bayesian Stochastic regression imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#predictive-mean-matching-or-regression-imputation"><i class="fa fa-check"></i><b>3.5</b> Predictive Mean Matching or Regression imputation</a><ul>
<li class="chapter" data-level="3.5.1" data-path="single-missing-data-imputations.html"><a href="single-missing-data-imputations.html#predictive-mean-matching-how-does-it-work"><i class="fa fa-check"></i><b>3.5.1</b> Predictive Mean Matching, how does it work?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-three-multiple-imputation.html"><a href="part-three-multiple-imputation.html"><i class="fa fa-check"></i>Part three - Multiple Imputation</a></li>
<li class="chapter" data-level="4" data-path="multiple-imputation.html"><a href="multiple-imputation.html"><i class="fa fa-check"></i><b>4</b> Multiple Imputation</a></li>
<li class="chapter" data-level="" data-path="part-iv-data-analysis-after-multiple-imputation.html"><a href="part-iv-data-analysis-after-multiple-imputation.html"><i class="fa fa-check"></i>Part IV – Data Analysis After Multiple Imputation</a></li>
<li class="chapter" data-level="5" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html"><i class="fa fa-check"></i><b>5</b> Data analysis after Multiple Imputation</a><ul>
<li class="chapter" data-level="5.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-results-after-mi-in-spss"><i class="fa fa-check"></i><b>5.1</b> Pooling results after MI in SPSS</a><ul>
<li class="chapter" data-level="5.1.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#imputed-values-are-yellow"><i class="fa fa-check"></i><b>5.1.1</b> Imputed values are yellow</a></li>
<li class="chapter" data-level="5.1.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#the-imputation_-variable"><i class="fa fa-check"></i><b>5.1.2</b> The Imputation_ variable</a></li>
<li class="chapter" data-level="5.1.3" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#special-pooling-icon"><i class="fa fa-check"></i><b>5.1.3</b> Special pooling icon</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-results-after-mi-in-r"><i class="fa fa-check"></i><b>5.2</b> Pooling results after MI in R</a></li>
<li class="chapter" data-level="5.3" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-means-and-standard-deviations-in-spss"><i class="fa fa-check"></i><b>5.3</b> Pooling Means and Standard deviations in SPSS</a></li>
<li class="chapter" data-level="5.4" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-means-and-standard-deviations-in-r"><i class="fa fa-check"></i><b>5.4</b> Pooling Means and Standard Deviations in R</a></li>
<li class="chapter" data-level="5.5" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-correlation-coefficients"><i class="fa fa-check"></i><b>5.5</b> Pooling Correlation coefficients</a><ul>
<li class="chapter" data-level="5.5.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-correlation-coefficients-in-spss"><i class="fa fa-check"></i><b>5.5.1</b> Pooling Correlation coefficients in SPSS</a></li>
<li class="chapter" data-level="5.5.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-correlation-coefficients-in-r"><i class="fa fa-check"></i><b>5.5.2</b> Pooling Correlation Coefficients in R</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#the-pooled-independent-t-test"><i class="fa fa-check"></i><b>5.6</b> The Pooled Independent T-test</a><ul>
<li class="chapter" data-level="5.6.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-independent-t-tests-in-spss"><i class="fa fa-check"></i><b>5.6.1</b> Pooling Independent T-tests in SPSS</a></li>
<li class="chapter" data-level="5.6.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-independent-t-tests-in-r-with-mice"><i class="fa fa-check"></i><b>5.6.2</b> Pooling Independent T-tests in R with mice</a></li>
<li class="chapter" data-level="5.6.3" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-independent-t-tests-in-r-with-mi.t.test"><i class="fa fa-check"></i><b>5.6.3</b> Pooling Independent T-tests in R with mi.t.test</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-chi-square-tests"><i class="fa fa-check"></i><b>5.7</b> Pooling Chi-square tests</a><ul>
<li class="chapter" data-level="5.7.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-chi-square-tests-in-spss"><i class="fa fa-check"></i><b>5.7.1</b> Pooling Chi-square tests in SPSS</a></li>
<li class="chapter" data-level="5.7.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-chi-square-tests-in-r"><i class="fa fa-check"></i><b>5.7.2</b> Pooling Chi-square tests in R</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#analysis-of-variance-anova-pooling"><i class="fa fa-check"></i><b>5.8</b> Analysis of Variance (ANOVA) pooling</a><ul>
<li class="chapter" data-level="5.8.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#analysis-of-variance-anova-pooling-in-spss"><i class="fa fa-check"></i><b>5.8.1</b> Analysis of Variance (ANOVA) pooling in SPSS</a></li>
<li class="chapter" data-level="5.8.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#analysis-of-variance-anova-pooling-in-r"><i class="fa fa-check"></i><b>5.8.2</b> Analysis of Variance (ANOVA) pooling in R</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-regression-models"><i class="fa fa-check"></i><b>5.9</b> Pooling Regression models</a><ul>
<li class="chapter" data-level="5.9.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-linear-regression-models-in-spss"><i class="fa fa-check"></i><b>5.9.1</b> Pooling Linear Regression Models in SPSS</a></li>
<li class="chapter" data-level="5.9.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-linear-regression-models-in-r"><i class="fa fa-check"></i><b>5.9.2</b> Pooling Linear regression models in R</a></li>
<li class="chapter" data-level="5.9.3" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-logistic-regression-models-in-spss"><i class="fa fa-check"></i><b>5.9.3</b> Pooling Logistic Regression models in SPSS</a></li>
<li class="chapter" data-level="5.9.4" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-logistic-regression-models-in-r"><i class="fa fa-check"></i><b>5.9.4</b> Pooling Logistic Regression models in R</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-logistic-regression-models-including-categorical-independent-variables"><i class="fa fa-check"></i><b>5.10</b> Pooling logistic regression models including categorical independent variables</a><ul>
<li class="chapter" data-level="5.10.1" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-cox-regression-models"><i class="fa fa-check"></i><b>5.10.1</b> Pooling Cox regression models</a></li>
<li class="chapter" data-level="5.10.2" data-path="data-analysis-after-multiple-imputation.html"><a href="data-analysis-after-multiple-imputation.html#pooling-cox-regression-models-in-spss"><i class="fa fa-check"></i><b>5.10.2</b> Pooling Cox regression models in SPSS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="more-topics-on-multiple-imputation-and-regression-modelling.html"><a href="more-topics-on-multiple-imputation-and-regression-modelling.html"><i class="fa fa-check"></i><b>6</b> More topics on Multiple Imputation and Regression Modelling</a></li>
<li class="chapter" data-level="" data-path="part-v-advanced-multiple-imputation-methods.html"><a href="part-v-advanced-multiple-imputation-methods.html"><i class="fa fa-check"></i>Part V – Advanced Multiple Imputation methods</a></li>
<li class="chapter" data-level="7" data-path="multiple-imputation-models-for-multilevel-data.html"><a href="multiple-imputation-models-for-multilevel-data.html"><i class="fa fa-check"></i><b>7</b> Multiple Imputation models for Multilevel data</a></li>
<li class="chapter" data-level="" data-path="part-vi-missing-data-in-questionnaires.html"><a href="part-vi-missing-data-in-questionnaires.html"><i class="fa fa-check"></i>Part VI – Missing Data in Questionnaires</a></li>
<li class="chapter" data-level="8" data-path="missing-data-in-questionnaires.html"><a href="missing-data-in-questionnaires.html"><i class="fa fa-check"></i><b>8</b> Missing Data in Questionnaires</a></li>
<li class="chapter" data-level="" data-path="background-information-to-multiple-imputation-methods.html"><a href="background-information-to-multiple-imputation-methods.html"><i class="fa fa-check"></i>Background information to Multiple Imputation Methods</a></li>
<li class="chapter" data-level="9" data-path="rubins-rules.html"><a href="rubins-rules.html"><i class="fa fa-check"></i><b>9</b> Rubin’s Rules</a><ul>
<li class="chapter" data-level="9.1" data-path="rubins-rules.html"><a href="rubins-rules.html#pooling-effect-estimates"><i class="fa fa-check"></i><b>9.1</b> Pooling Effect estimates</a></li>
<li class="chapter" data-level="9.2" data-path="rubins-rules.html"><a href="rubins-rules.html#pooling-standard-errors"><i class="fa fa-check"></i><b>9.2</b> Pooling Standard errors</a></li>
<li class="chapter" data-level="9.3" data-path="rubins-rules.html"><a href="rubins-rules.html#significance-testing"><i class="fa fa-check"></i><b>9.3</b> Significance testing</a></li>
<li class="chapter" data-level="9.4" data-path="rubins-rules.html"><a href="rubins-rules.html#degrees-of-freedom-and-p-values"><i class="fa fa-check"></i><b>9.4</b> Degrees of Freedom and P-values</a></li>
<li class="chapter" data-level="9.5" data-path="rubins-rules.html"><a href="rubins-rules.html#confidence-intervals"><i class="fa fa-check"></i><b>9.5</b> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="measures-of-missing-data-information.html"><a href="measures-of-missing-data-information.html"><i class="fa fa-check"></i><b>10</b> Measures of Missing data information</a><ul>
<li class="chapter" data-level="10.1" data-path="measures-of-missing-data-information.html"><a href="measures-of-missing-data-information.html#fraction-of-missing-information---lambda"><i class="fa fa-check"></i><b>10.1</b> Fraction of Missing Information - Lambda</a></li>
<li class="chapter" data-level="10.2" data-path="measures-of-missing-data-information.html"><a href="measures-of-missing-data-information.html#relative-increase-in-variance"><i class="fa fa-check"></i><b>10.2</b> Relative increase in variance</a></li>
<li class="chapter" data-level="10.3" data-path="measures-of-missing-data-information.html"><a href="measures-of-missing-data-information.html#fraction-of-missing-information---fmi"><i class="fa fa-check"></i><b>10.3</b> Fraction of Missing Information - FMI</a></li>
<li class="chapter" data-level="10.4" data-path="measures-of-missing-data-information.html"><a href="measures-of-missing-data-information.html#relative-efficiency"><i class="fa fa-check"></i><b>10.4</b> Relative Efficiency</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pooling-correlation-coefficients-1.html"><a href="pooling-correlation-coefficients-1.html"><i class="fa fa-check"></i><b>11</b> Pooling correlation coefficients</a><ul>
<li class="chapter" data-level="11.1" data-path="pooling-correlation-coefficients-1.html"><a href="pooling-correlation-coefficients-1.html#pooled-wald-test"><i class="fa fa-check"></i><b>11.1</b> Pooled Wald test</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Missing data analysis with SPSS and R(Studio)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data-analysis-after-multiple-imputation" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Data analysis after Multiple Imputation</h1>
<div id="pooling-results-after-mi-in-spss" class="section level2">
<h2><span class="header-section-number">5.1</span> Pooling results after MI in SPSS</h2>
<div id="imputed-values-are-yellow" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Imputed values are yellow</h3>
<p>After multiple imputation, the multiple imputed datasets are stored in a new SPSS file. In order to obtain pooled analysis results, the imputed values must be marked yellow. Than SPSS recognizes the dataset is an “imputed” dataset and is able to generate pooled analyses results. Figure <a href="data-analysis-after-multiple-imputation.html#fig:fig5-1">5.1</a>) shows an example of a multiple imputed dataset with imputed values marked yellow. If SPSS does not recognize the dataset as a multiple imputed dataset, the data will be treated as one large dataset.</p>
<div class="figure" style="text-align: center"><span id="fig:fig5-1"></span>
<img src="images/fig5.1.png" alt="Example of SPSS dataset after MI has been applied." width="90%" />
<p class="caption">
Figure 5.1: Example of SPSS dataset after MI has been applied.
</p>
</div>
<p>You can mark the imputed values by using the option “Mark Imputed Data” under the View menu in the Data View window ((Figure <a href="data-analysis-after-multiple-imputation.html#fig:fig5-1">5.1</a>)).</p>
</div>
<div id="the-imputation_-variable" class="section level3">
<h3><span class="header-section-number">5.1.2</span> The Imputation_ variable</h3>
<p>The Imputation_ variable is a nominal variable that separates the original from the imputed datasets. It is used as a variable that splits the file into separate groups for analysis based on the different categories. This is also indicated in the corner on the right side below in the Data View and Variable View windows by the note “Split by imputation_”.</p>
<div class="figure" style="text-align: center"><span id="fig:fig5-2"></span>
<img src="images/fig5.2.png" alt="Procedure to mark imputed values in SPSS." width="90%" />
<p class="caption">
Figure 5.2: Procedure to mark imputed values in SPSS.
</p>
</div>
<p>When missing values are imputed with any another software program, you can include an Imputation_ variable in SPSS. It is than recognized as an imputed dataset in SPSS.</p>
</div>
<div id="special-pooling-icon" class="section level3">
<h3><span class="header-section-number">5.1.3</span> Special pooling icon</h3>
<p>When imputation markings are turned on, a special icon is displayed next to the statistical procedures in the analyze menu. This icon shows you if a pooled result is generated after multiple imputation is used ((Figure <a href="data-analysis-after-multiple-imputation.html#fig:fig5-3">5.3</a>)).</p>
<div class="figure" style="text-align: center"><span id="fig:fig5-3"></span>
<img src="images/fig5.3.png" alt="Multiple Imputation icon." width="5%" />
<p class="caption">
Figure 5.3: Multiple Imputation icon.
</p>
</div>
<p>This icon is shown in the analyze menu in SPSS (Figure <a href="data-analysis-after-multiple-imputation.html#fig:fig5-4b">5.4</a>)).</p>
<div class="figure" style="text-align: center"><span id="fig:fig5-4b"></span>
<img src="images/fig5.4b.png" alt="The dataset is recognized as an imputed dataset (special icon visible)." width="90%" />
<p class="caption">
Figure 5.4: The dataset is recognized as an imputed dataset (special icon visible).
</p>
</div>
<p>SPSS provides two levels of pooling, which are called the Naïve and Univariate combination. The Naïve combination only shows the pooled parameter (if available). The Univariate combination shows the pooled parameter, its standard error, test statistic, effective degrees of freedom, p-value, confidence interval, and pooling diagnostics (fraction of missing information, relative efficiency, relative increase in variance), when available. Although the special icon in SPSS to indicate that the dataset is recognized as a multiple imputed dataset appears for many analysis procedures, it is not always clear what procedures really provide the Univariate combination output. It is therefore recommended to explore what kind of pooled information is provided by SPSS before MI is applied.</p>
</div>
</div>
<div id="pooling-results-after-mi-in-r" class="section level2">
<h2><span class="header-section-number">5.2</span> Pooling results after MI in R</h2>
<p>Many pooling procedures are available as part of the mice package. However, for some specific statistical procedures, other packages are required to obtain pooled estimates. For example, pooling ANOVA results is not available in the mice package itself. For this, the miceadds package has to be used.</p>
<p>For the examples in this Chapter We will use three imputed datasets, to keep the output Tables readable, although the examples easily generalize to a larger number of imputed datasets.</p>
</div>
<div id="pooling-means-and-standard-deviations-in-spss" class="section level2">
<h2><span class="header-section-number">5.3</span> Pooling Means and Standard deviations in SPSS</h2>
<p>To get pooled means you just use</p>
<blockquote>
<p>Analyze &gt; Descriptive Statistics.</p>
</blockquote>
<p>Figure <a href="data-analysis-after-multiple-imputation.html#fig:tab5-3">5.5</a> shows that in the “Pooled” row the mean values of the Tampascale variable are pooled. The standard deviations are not automatically pooled in SPSS. The mean value of the standard deviations can be calculated by computing the average over the standard deviations.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-3"></span>
<img src="images/table5.3.png" alt="Pooling results of descriptive statistics." width="90%" />
<p class="caption">
Figure 5.5: Pooling results of descriptive statistics.
</p>
</div>
</div>
<div id="pooling-means-and-standard-deviations-in-r" class="section level2">
<h2><span class="header-section-number">5.4</span> Pooling Means and Standard Deviations in R</h2>
<p>To pool the means and standard deviations you use the with function in mice.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the SPSS dataset</span>
<span class="kw">library</span>(foreign)
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 Missing MI datasets.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mice)
<span class="co"># Apply multiple imputation</span>
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2375</span>, <span class="dt">printFlag =</span> F)
 
<span class="co"># Stack imputed datasets in long format, exclude the original data</span>
impdat &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dt">action=</span><span class="st">&quot;long&quot;</span>,<span class="dt">include =</span> <span class="ot">FALSE</span>)

<span class="co"># compute mean and standard deviation in each imputed dataset</span>
desc &lt;-<span class="st"> </span><span class="kw">with</span>(impdat, <span class="kw">by</span>(impdat, .imp, <span class="cf">function</span>(x) <span class="kw">c</span>(<span class="kw">mean</span>(x<span class="op">$</span>Tampascale),<span class="kw">sd</span>(x<span class="op">$</span>Tampascale))))
desc</code></pre></div>
<pre><code>## .imp: 1
## [1] 38.935000  5.330867
## -------------------------------------------------------- 
## .imp: 2
## [1] 38.988333  5.400321
## -------------------------------------------------------- 
## .imp: 3
## [1] 38.998333  5.391361</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Reduce</span>(<span class="st">&quot;+&quot;</span>,desc)<span class="op">/</span><span class="kw">length</span>(desc)</code></pre></div>
<pre><code>## [1] 38.973889  5.374183</code></pre>
</div>
<div id="pooling-correlation-coefficients" class="section level2">
<h2><span class="header-section-number">5.5</span> Pooling Correlation coefficients</h2>
<p>When a normal distribution of the parameter estimates cannot be assumed, like for the correlation coefficients, a Fishers Z transformation has to be performed before pooling (see the appendix for the formula’s). This is automatically done in SPSS and R.</p>
<div id="pooling-correlation-coefficients-in-spss" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Pooling Correlation coefficients in SPSS</h3>
<p>A pooled Pearsons correlation coefficient between for example, the Tampascale and Age variables can be extracted using</p>
<blockquote>
<p>Analyse -&gt; Correlate -&gt; Bivariate.</p>
</blockquote>
<p>Than transfer the variable Tampa scale and Age to the variables window and click on OK. The pooled results are shown in (Figure <a href="data-analysis-after-multiple-imputation.html#fig:tab5-4">5.6</a>), in the row called Pooled. The pooled correlation is 0.255, and the significance level is 0.002. These correlations are calculated using Fishers Z transformation before pooling and after pooling they are back-transformed.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-4"></span>
<img src="images/table5.4.png" alt="Pearson correlation between the Tampascale variable and Age." width="90%" />
<p class="caption">
Figure 5.6: Pearson correlation between the Tampascale variable and Age.
</p>
</div>
</div>
<div id="pooling-correlation-coefficients-in-r" class="section level3">
<h3><span class="header-section-number">5.5.2</span> Pooling Correlation Coefficients in R</h3>
<p>You can use the micombine.cor function in the miceadds package to obtain pooled correlation coefficients.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the dataset </span>
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Impute missing data using the mice function, with printFlag is F(alse), </span>
<span class="co"># which means that the imp and iter information is hided (called silent </span>
<span class="co"># computation)</span>
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2375</span>, <span class="dt">printFlag=</span>F)

<span class="co"># Run the micombine.cor function for the variables in column 2 </span>
<span class="co"># and 5, i.e. variables Tampascale and Age</span>
res.mi.cor &lt;-<span class="st"> </span><span class="kw">micombine.cor</span>(<span class="dt">mi.res=</span>imp, <span class="dt">variables =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">5</span>) )
res.mi.cor</code></pre></div>
<pre><code>##    variable1  variable2        r        rse  fisher_r fisher_rse
## 1 Tampascale        Age 0.252762 0.07748072 0.2583611 0.08278965
## 2        Age Tampascale 0.252762 0.07748072 0.2583611 0.08278965
##           fmi        t           p    lower95   upper95
## 1 0.007555655 3.120693 0.001804258 0.09580167 0.3974575
## 2 0.007555655 3.120693 0.001804258 0.09580167 0.3974575</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Ouput of the micombine.cor function, with in the columns:</span>
<span class="co">#   r: Pooled Pearsons correlation coefficient.</span>
<span class="co">#     rse: Standard error of pooled correlation.</span>
<span class="co">#     fisher_r: Transformed pooled r</span>
<span class="co">#     fisher_rse: Standard error of transformed pooled r</span>
<span class="co">#     fmi: Fraction of missing information.</span>
<span class="co">#     t: T-value.</span>
<span class="co">#     p: P-value.</span>
<span class="co">#     lower95 and upper95: 95% lower and upper confidence intervals.</span></code></pre></div>
</div>
</div>
<div id="the-pooled-independent-t-test" class="section level2">
<h2><span class="header-section-number">5.6</span> The Pooled Independent T-test</h2>
<p>To pool the independent t-test, Rubin´s Rules can be used. These steps are discussed in detail, including the formula’s to get the results, in Chapter 9.</p>
<div id="pooling-independent-t-tests-in-spss" class="section level3">
<h3><span class="header-section-number">5.6.1</span> Pooling Independent T-tests in SPSS</h3>
<p>To get a pooled t-test result to estimate the difference in mean Tampascale values between patients with and without Radiation in the leg you go to:</p>
<blockquote>
<p>Analyze -&gt; Compare Means -&gt; Independent-Samples T Test</p>
</blockquote>
<p>Transport the Tampa Scale variable to the Test Variable(s) window and the Radiation variable to the Grouping Variable window. Than Click on Define Groups and Define Group 1 as “1” and Group 2 as “0”. Than Click on Continue and OK. The following output table will show up, Figure <a href="data-analysis-after-multiple-imputation.html#fig:tab5-1a">5.7</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-1a"></span>
<img src="images/table5.1.png" alt="T-test for difference in mean Tampascale values between patients with and without Radiation in the leg applied in multiple imputed datasets." width="90%" />
<p class="caption">
Figure 5.7: T-test for difference in mean Tampascale values between patients with and without Radiation in the leg applied in multiple imputed datasets.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:tab5-1b"></span>
<img src="images/table5.1b.png" alt="b.T-test for difference in mean Tampascale values between patients with and without Radiation in the leg applied in multiple imputed datasets." width="90%" />
<p class="caption">
Figure 5.8: b.T-test for difference in mean Tampascale values between patients with and without Radiation in the leg applied in multiple imputed datasets.
</p>
</div>
<p>The result in the original dataset (including missing values) is presented in the row that is indicated by Imputation_ number 0. Results in each imputed dataset are shown in the rows starting with number 1 to 3. In the last row which is indicated as “Pooled”, the summary estimates of the mean differences, standard errors, p-values and 95% Confidence Interval are presented.</p>
</div>
<div id="pooling-independent-t-tests-in-r-with-mice" class="section level3">
<h3><span class="header-section-number">5.6.2</span> Pooling Independent T-tests in R with mice</h3>
<p>The mice package itself does not have a pooled t-test option. Instead a linear regression analysis has to be conducted. A linear regression analysis with a continuous outcome variable and an independent dichotomous variable is the same procedure as an independent t-test. Use for this the lm procedure in mice with as independent variable Radiation and dependent variable Tampascale.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Reading in the dataset</span>
<span class="kw">library</span>(foreign)
<span class="kw">library</span>(mice)

dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Impute the missing values using the mice function </span>
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2375</span>, <span class="dt">printFlag=</span>F)
 
<span class="co"># Conduct an independent t-test via lm in each imputed dataset</span>
fit.t.test &lt;-<span class="st"> </span><span class="kw">with</span>(<span class="dt">data=</span>imp, <span class="dt">exp=</span><span class="kw">lm</span>(Tampascale <span class="op">~</span><span class="st"> </span>Radiation))
t.test.estimates &lt;-<span class="st"> </span><span class="kw">pool</span>(fit.t.test)
<span class="kw">summary</span>(t.test.estimates)</code></pre></div>
<pre><code>##              estimate std.error statistic       df    p.value
## (Intercept) 38.153846 0.5628260  67.78977 141.2188 0.00000000
## Radiation    1.993047 0.9205375   2.16509 106.3217 0.03206084</code></pre>
<p>We see in the output, under est and se the same values as in SPSS (Figure <a href="data-analysis-after-multiple-imputation.html#fig:tab5-4">5.6</a>), the pooled value of 1.97 and 0.92 for the mean difference and standard error respectively.</p>
<p>Under the column df in R you see that the dfs for the mean differences in the Tampascale variable are much smaller than those in (Figure <a href="data-analysis-after-multiple-imputation.html#fig:tab5-4">5.6</a>) above. This is due to the different formulas used to calculate the df. SPSS uses an older version and mice an adjusted one (see Chapter 9 for more information about different ways to calculate the df between SPSS and R)</p>
</div>
<div id="pooling-independent-t-tests-in-r-with-mi.t.test" class="section level3">
<h3><span class="header-section-number">5.6.3</span> Pooling Independent T-tests in R with mi.t.test</h3>
<p>you can also use the mi.t.test function in the MKmisc package. Note that the mi.t.test function uses the parameter setting var.equal is True when equal variances are assumed and var.equal is False when equal variances are not assumed (the default setting is var.equal is False).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the dataset</span>
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use the mice function to impute the missing data</span>
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2375</span>, <span class="dt">printFlag=</span>F)
 
<span class="co"># Extract the imputed datasets and define the Radiation variable  </span>
<span class="co"># as a factor variable</span>
dataset1 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">1</span>)
dataset1<span class="op">$</span>Radiation &lt;-<span class="st"> </span><span class="kw">factor</span>(dataset1<span class="op">$</span>Radiation)
dataset2 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">2</span>)
dataset2<span class="op">$</span>Radiation &lt;-<span class="st"> </span><span class="kw">factor</span>(dataset2<span class="op">$</span>Radiation)
dataset3 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">3</span>)
dataset3<span class="op">$</span>Radiation &lt;-<span class="st"> </span><span class="kw">factor</span>(dataset3<span class="op">$</span>Radiation)
 
<span class="co"># Assign the imputed datasets to the list object dataset.imp</span>
dataset.imp &lt;-<span class="st"> </span><span class="kw">list</span>(dataset1, dataset2, dataset3)
 
<span class="co"># Start the MKmisc library and run the mi.t.test function to get pooled </span>
<span class="co"># results  of the t-test</span>
<span class="kw">library</span>(MKmisc)

<span class="co"># Result of the pooled t-test</span>
<span class="kw">mi.t.test</span>(dataset.imp, <span class="dt">x =</span> <span class="st">&quot;Tampascale&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Radiation&quot;</span>, <span class="dt">var.equal =</span> T)</code></pre></div>
<pre><code>## 
##  Multiple Imputation Two Sample t-test
## 
## data:  Variable Tampascale: group 0 vs group 1
## t = -2.1651, df = 106.32, p-value = 0.03262
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -3.8180378 -0.1680552
## sample estimates:
##  mean (0)    SD (0)  mean (1)    SD (1) 
## 38.153846  5.597451 40.146893  5.198414</code></pre>
<p>With the mi.t.test function also a one sample and a paired t-test can be conducted.</p>
</div>
</div>
<div id="pooling-chi-square-tests" class="section level2">
<h2><span class="header-section-number">5.7</span> Pooling Chi-square tests</h2>
<div id="pooling-chi-square-tests-in-spss" class="section level3">
<h3><span class="header-section-number">5.7.1</span> Pooling Chi-square tests in SPSS</h3>
<p>The pooling of Chi-square values as a result of the Chi-square test is not available in SPSS. This lack of reporting of the Chi-Square test is shown in (Figure <a href="data-analysis-after-multiple-imputation.html#fig:tab5-6">5.9</a>) where the association between the Tampa scale variable as a categorical variable (with the categories 0 = low fear of movement, 1 = middle fear of movement and 2 is a high fear of movement) and Radiation in the leg is studied. The Chi-square test is presented in the original dataset and in each imputed dataset, but a pooled Chi-square value and pooled p-value is missing. This is remarkable because when you choose for Descriptive Statistics -&gt; Crosstabs to conduct the Chi-square test the special Multiple Imputation icon is shown. This is an indication that you get pooled results, however in this case it is not.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-6"></span>
<img src="images/table5.6.png" alt="Chi-square test in 5 imputed dataset to test the relationship between the Tampascale variable and Radiation, where a pooled estimate is missing." width="90%" />
<p class="caption">
Figure 5.9: Chi-square test in 5 imputed dataset to test the relationship between the Tampascale variable and Radiation, where a pooled estimate is missing.
</p>
</div>
</div>
<div id="pooling-chi-square-tests-in-r" class="section level3">
<h3><span class="header-section-number">5.7.2</span> Pooling Chi-square tests in R</h3>
<p>Procedures to pool Chi-square values are available in the miceadds package. The pooling functions are based on formulas that can be found in Marshall (2009) and Enders (2012) and are referred to as the D2 statistic. To pool the Chi-square values of the SPSS example you use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(miceadds)
<span class="kw">micombine.chisquare</span>(<span class="kw">c</span>(<span class="fl">1.829</span>, <span class="fl">1.311</span>, <span class="fl">2.861</span>, <span class="fl">1.771</span>, <span class="fl">3.690</span>), <span class="dv">2</span>, <span class="dt">display =</span> <span class="ot">TRUE</span>, <span class="dt">version=</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## Combination of Chi Square Statistics for Multiply Imputed Data
## Using 5 Imputed Data Sets
## F(2, 240.99)=0.869     p=0.42056</code></pre>
<p>The function micombine.chisquare also has a parameter setting that is called “version”. The default version=1 refers to the correct formula as in Enders (2010), while version=0 uses an incorrect formula as printed in Allison (2001).</p>
</div>
</div>
<div id="analysis-of-variance-anova-pooling" class="section level2">
<h2><span class="header-section-number">5.8</span> Analysis of Variance (ANOVA) pooling</h2>
<div id="analysis-of-variance-anova-pooling-in-spss" class="section level3">
<h3><span class="header-section-number">5.8.1</span> Analysis of Variance (ANOVA) pooling in SPSS</h3>
<p>The pooling of Analysis of Variance (ANOVA) statistics is not available in SPSS. In Figure <a href="data-analysis-after-multiple-imputation.html#fig:tab5-7">5.10</a> the table is shown as a result of ANOVA after multiple imputation. It is clear from the Figure that the pooled results are lacking.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-7"></span>
<img src="images/table5.7.png" alt="ANOVA in SPSS without a pooled result." width="90%" />
<p class="caption">
Figure 5.10: ANOVA in SPSS without a pooled result.
</p>
</div>
</div>
<div id="analysis-of-variance-anova-pooling-in-r" class="section level3">
<h3><span class="header-section-number">5.8.2</span> Analysis of Variance (ANOVA) pooling in R</h3>
<p>The pooled ANOVA procedure uses the same function as was used in the previous paragraph to derive the pooled Chi-square value, because the Chi and the F-value are related. The easiest way to obtain a p-value for the ANOVA is by using the mi.anova function in the miceadds package. In this function a regression based formula can be defined to get a p-value.</p>
<p>To compare the Function means between three Tampascale variable groups, you use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the dataset</span>
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 Missing_Tampa_Cat.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate 5 impued datasets </span>
<span class="co"># and set printFlag = F for a silent imputation</span>
imp.Tampa.cat &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">5</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2345</span>, <span class="dt">printFlag =</span> F)

<span class="co"># Apply the mi.anova function</span>
<span class="kw">library</span>(miceadds)
<span class="kw">mi.anova</span>(<span class="dt">mi.res=</span>imp.Tampa.cat, <span class="dt">formula=</span><span class="st">&quot;Function ~ Tampa_Cat&quot;</span> )</code></pre></div>
<pre><code>## Univariate ANOVA for Multiply Imputed Data (Type 2)  
## 
## lm Formula:  Function ~ Tampa_Cat
## R^2=0.1494 
## ..........................................................................
## ANOVA Table 
##                   SSQ df1      df2 F value Pr(&gt;F)    eta2 partial.eta2
## Tampa_Cat    427.7156   1 100.1874 20.5678  2e-05 0.14943      0.14943
## Residual    2434.6298  NA       NA      NA     NA      NA           NA</code></pre>
<p>The pooled F and p-values are reported under the columns F value and Pr(&gt;F) respectively.</p>
</div>
</div>
<div id="pooling-regression-models" class="section level2">
<h2><span class="header-section-number">5.9</span> Pooling Regression models</h2>
<div id="pooling-linear-regression-models-in-spss" class="section level3">
<h3><span class="header-section-number">5.9.1</span> Pooling Linear Regression Models in SPSS</h3>
<p>To pool the results from a linear regression analysis Rubin´s Rules are used. To study the relationship between the Tampascale (independent) and Function (dependent) variables go to:</p>
<blockquote>
<p>Analyze -&gt; Regression -&gt; Linear.</p>
</blockquote>
<p>Transport the variable Function to the Dependent window and the Tampa scale variable to the Independent(s) window. To get pooled 95% Confidence Intervals, go to Statistics and select the Confidence Intervals option. Than click on Continue and OK.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-8"></span>
<img src="images/table5.8.png" alt="Relationship between Tampascale and Function estimated with linear regression in SPSS." width="90%" />
<p class="caption">
Figure 5.11: Relationship between Tampascale and Function estimated with linear regression in SPSS.
</p>
</div>
<p>Information is provided in the row called Pooled about the parameter estimates, i.e. regression coefficients, standard errors, t-values, p-values and confidence interval. Further, information is provided about the Fraction of Missing Information, Relative Increase Variance and Relative Efficiency.</p>
</div>
<div id="pooling-linear-regression-models-in-r" class="section level3">
<h3><span class="header-section-number">5.9.2</span> Pooling Linear regression models in R</h3>
<p>A pooled linear regression analyses can be produced by using the with and pool functions in the mice package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">3715</span>, <span class="dt">printFlag=</span>F)

fit &lt;-<span class="st"> </span><span class="kw">with</span>(<span class="dt">data=</span>imp,<span class="dt">exp=</span><span class="kw">lm</span>(Function <span class="op">~</span><span class="st"> </span>Tampascale))
lin.pool &lt;-<span class="st"> </span><span class="kw">pool</span>(fit)
<span class="kw">summary</span>(lin.pool)</code></pre></div>
<pre><code>##              estimate  std.error statistic       df     p.value
## (Intercept) 26.307730 3.51479517  7.484854 6.671497 0.000176412
## Tampascale  -0.375401 0.09252282 -4.057388 5.963136 0.005338392</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Results of the pooled procedure, with:</span>
<span class="co">#   est: Pooled regression coefficient.</span>
<span class="co">#   se: Standard error of pooled regression coefficient.</span>
<span class="co">#   t: T-value.</span>
<span class="co">#   df: Degrees of freedom.</span>
<span class="co">#   Pr(&gt;|t|): P-value.</span>
<span class="co">#   lo 95 and hi 95: 95% lower and upper confidence intervals.</span>
<span class="co">#   nmis: number of missing observations.</span>
<span class="co">#   fmi: fraction of missing information.</span>
<span class="co">#   Lambda: Proportion of the variation attributable to the missing data </span></code></pre></div>
</div>
<div id="pooling-logistic-regression-models-in-spss" class="section level3">
<h3><span class="header-section-number">5.9.3</span> Pooling Logistic Regression models in SPSS</h3>
<p>To study the relationship between the variables Function (independent variable) and Radiation in the Leg (dependent variable we need Logistic regression. This procedure can be done in SPSS via</p>
<blockquote>
<p>Analyze -&gt; Regression -&gt; Binary Logistic.</p>
</blockquote>
<p>Transport the variable Radiation in the Leg to the Dependent window and the Function variable to the Covariates window. To get pooled 95% Confidence Intervals, go to Options and select the CI for exp(B) option. Than click on Continue and OK.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-9"></span>
<img src="images/table5.9.png" alt="Logistic Regression in SPSS." width="90%" />
<p class="caption">
Figure 5.12: Logistic Regression in SPSS.
</p>
</div>
<p>information is provided in the row called Pooled about the parameter estimates, i.e. regression coefficients (B), standard errors (S.E.), p-values (Sig.), odds ratio´s (Exp(B) and 95% confidence intervals around the OR (95% C.I. for EXP(B). Further, information is provided about the Fraction of Missing Information, Relative Increase Variance and Relative Efficiency. For the pooled coefficient and standard error Rubin´s Rules (RR) are used.</p>
</div>
<div id="pooling-logistic-regression-models-in-r" class="section level3">
<h3><span class="header-section-number">5.9.4</span> Pooling Logistic Regression models in R</h3>
<p>You can use mice to get pooled results after logistic regression. In combination with the pool function you have to use the following R code.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp.LR &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2268</span>, <span class="dt">printFlag =</span> <span class="ot">FALSE</span>)
fit &lt;-<span class="st"> </span><span class="kw">with</span>(<span class="dt">data=</span>imp.LR, <span class="dt">exp=</span><span class="kw">glm</span>(Radiation <span class="op">~</span><span class="st"> </span>Function, <span class="dt">family =</span> binomial))
<span class="kw">summary</span>(<span class="kw">pool</span>(fit))</code></pre></div>
<pre><code>##                estimate  std.error  statistic       df   p.value
## (Intercept)  0.33331305 0.54023681  0.6169758 30.48361 0.5418318
## Function    -0.06669438 0.04498345 -1.4826425 26.76133 0.1484349</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#   Results of the pooled procedure, with:</span>
<span class="co">#   est: Pooled regression coefficient.</span>
<span class="co">#   se: Standard error of pooled regression coefficient.</span>
<span class="co">#   t: T-value.</span>
<span class="co">#   df: Degrees of freedom.</span>
<span class="co">#   Pr(&gt;|t|): P-value.</span>
<span class="co">#   lo 95 and hi 95: 95% lower and upper confidence intervals.</span>
<span class="co">#   nmis: number of missing observations.</span>
<span class="co">#   fmi: fraction of missing information.</span>
<span class="co">#   Lambda: Proportion of the variation attributable to the missing data </span></code></pre></div>
<p>Under the Line with the R code summary(pool(fit)), the pooled estimates are provided. To extract the ORs and the corresponding 95% Confidence intervals you have to apply the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#summary.fit &lt;- summary(pool(fit))</span>
<span class="co">#pool.OR &lt;- exp(cbind(summary.fit[,1],summary.fit[,6],summary.fit[,7]))</span>
<span class="co">#colnames(pool.OR) &lt;- (c(&quot;OR&quot;, &quot;95% LO&quot;, &quot;95% UP&quot;))</span>
<span class="co">#pool.OR</span></code></pre></div>
<p>Another procedure to get the pooled estimates from a logistic regression model is by using the micombine function in the mitools package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mitools)
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2268</span>, <span class="dt">printFlag =</span> F)
dataset1 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">1</span>)
dataset2 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">2</span>)
dataset3 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">3</span>)
 
dataset.imp &lt;-<span class="st"> </span><span class="kw">list</span>(dataset1, dataset2, dataset3)
 
imp.LR &lt;-<span class="st"> </span><span class="kw">lapply</span>(dataset.imp, <span class="cf">function</span>(x) {
   <span class="kw">glm</span>(Radiation <span class="op">~</span><span class="st"> </span>Function, <span class="dt">family =</span> binomial, <span class="dt">data =</span> x)
  })
coef &lt;-<span class="st"> </span><span class="kw">MIextract</span>(imp.LR, <span class="dt">fun=</span>coef) 
se &lt;-<span class="st"> </span><span class="kw">MIextract</span>(imp.LR, <span class="dt">fun=</span>vcov) 
 
summary.fit &lt;-<span class="st"> </span><span class="kw">summary</span>(<span class="kw">MIcombine</span>(coef, se) )</code></pre></div>
<pre><code>## Multiple imputation results:
##       MIcombine.default(coef, se)
##                 results         se     (lower     upper) missInfo
## (Intercept)  0.33331305 0.54023681 -0.7572339 1.42385997     25 %
## Function    -0.06669438 0.04498345 -0.1579936 0.02460484     28 %</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pool.OR &lt;-<span class="st"> </span><span class="kw">exp</span>(summary.fit[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">5</span>)]) 
<span class="kw">colnames</span>(pool.OR) &lt;-<span class="st"> </span>(<span class="kw">c</span>(<span class="st">&quot;OR&quot;</span>, <span class="st">&quot;95% LO&quot;</span>, <span class="st">&quot;95% UP&quot;</span>))
pool.OR</code></pre></div>
<pre><code>##                    OR    95% LO  95% UP
## (Intercept) 1.3955841 0.4689618 4.15312
## Function    0.9354811 0.8538552 1.02491</code></pre>
<p>However, the pooled p-value is still missing. You can get the pooled p-values from the mi.inference function in the NORM package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(norm)
se &lt;-<span class="st"> </span><span class="kw">lapply</span>(se, <span class="cf">function</span>(x) <span class="kw">sqrt</span>(<span class="kw">diag</span>(x)) )
 
res &lt;-<span class="st"> </span><span class="kw">mi.inference</span>(coef,se)
res.pool &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">unlist</span>(res), <span class="dv">2</span>, <span class="dv">8</span>, <span class="dt">byrow=</span>F)
<span class="kw">colnames</span>(res.pool) &lt;-<span class="st"> </span><span class="kw">names</span>(res)
<span class="kw">rownames</span>(res.pool) &lt;-<span class="st"> </span><span class="kw">names</span>(res<span class="op">$</span>est)
res.pool</code></pre></div>
<pre><code>##                     est    std.err       df    signif      lower
## (Intercept)  0.33331305 0.54023681 41.60735 0.5406124 -0.7572339
## Function    -0.06669438 0.04498345 35.23806 0.1470584 -0.1579936
##                  upper         r     fminf
## (Intercept) 1.42385997 0.2808117 0.2542508
## Function    0.02460484 0.3127440 0.2780801</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pool.OR &lt;-<span class="st"> </span><span class="kw">exp</span>(res.pool[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">8</span>)]) 
<span class="kw">colnames</span>(pool.OR) &lt;-<span class="st"> </span>(<span class="kw">c</span>(<span class="st">&quot;OR&quot;</span>, <span class="st">&quot;95% LO&quot;</span>, <span class="st">&quot;95% UP&quot;</span>))
pool.OR</code></pre></div>
<pre><code>##                    OR    95% LO  95% UP
## (Intercept) 1.3955841 0.4689618 4.15312
## Function    0.9354811 0.8538552 1.02491</code></pre>
<p>The p-value in the NORM package is equal to the p-value in SPSS. This means that the NORM package also uses the older method to calculate the degrees of freedom.</p>
</div>
</div>
<div id="pooling-logistic-regression-models-including-categorical-independent-variables" class="section level2">
<h2><span class="header-section-number">5.10</span> Pooling logistic regression models including categorical independent variables</h2>
<p>For categorical variables in logistic regression models, different methods are available to test the variable as a whole for significance. These so called Multiparameter tests are not available in SPSS, but they are available in R. These tests will be discussed in the next Chapter. We will start with an example of univariate pooling in SPSS.</p>
<div id="pooling-cox-regression-models" class="section level3">
<h3><span class="header-section-number">5.10.1</span> Pooling Cox regression models</h3>
<p>One of the most used statistical models for survival data is the Cox regression model. With survival data you have two outcome measures, the status variable and the time to event variable. As a guideline, all variables of the main analysis, including the outcome variable have to be part of the imputation model. The best way to include the outcome variable in a Cox regression model is not by using the Time variable itself, but by using the cumulative hazard to the survival time. This value has to be included in the imputation model together with the status variable and the auxiliary variables.</p>
</div>
<div id="pooling-cox-regression-models-in-spss" class="section level3">
<h3><span class="header-section-number">5.10.2</span> Pooling Cox regression models in SPSS</h3>
<p>The cumulative hazard value can easily be calculated in SPSS by using the Survival menu and then choose for</p>
<blockquote>
<p>Analyze -&gt; Cox Regression</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:fig5-5"></span>
<img src="images/fig5.5.png" alt="The survival options in SPSS." width="90%" />
<p class="caption">
Figure 5.13: The survival options in SPSS.
</p>
</div>
<p>Than choose for Save and the following window will open.</p>
<div class="figure" style="text-align: center"><span id="fig:fig5-6"></span>
<img src="images/fig5.6.png" alt="The Save menu under Cox regression." width="90%" />
<p class="caption">
Figure 5.14: The Save menu under Cox regression.
</p>
</div>
<p>Here you can choose for Hazard function. Then click on Continue and OK. A new variable will we added to the dataset, which is called HZA_1. This cumulative hazard variable can be included in the imputation model to impute missing data in the Pain variable.</p>
<p>The pooling of the Cox regression model will be done in the datasets that are imputed in R. Than we can compare the output from the pooled model in SPSS and in R.</p>
<p>To get pooled results of Cox regression models you use:</p>
<blockquote>
<p>Analyze -&gt; Survival -&gt; Cox Regression</p>
</blockquote>
<p>Transport the survival time variable to Time window, the event variable to the Status window and the independent variable Pain to the Covariates window. To get pooled 95% Confidence Intervals, go to Options and select the CI for exp(B) option. Than click on Continue and OK.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-10"></span>
<img src="images/table5.10.png" alt="The pooled Cox regression model estimated in SPSS." width="90%" />
<p class="caption">
Figure 5.15: The pooled Cox regression model estimated in SPSS.
</p>
</div>
<p>This procedure provides a pooled value for the regression coefficient, standard error, p-value (of 0.000589), hazard ratio and related 95% confidence intervals and provides information about the fraction of missing information, the relative increase in variance and the relative efficiency.</p>
<div id="pooling-cox-regression-models-in-r" class="section level4">
<h4><span class="header-section-number">5.10.2.1</span> Pooling Cox regression models in R</h4>
<p>For this procedure we can make use of the pool function that is available in the mice package.</p>
<p>We start by using the mice function to impute missing data in the Pain variable by first calculating the cumulative hazard values. After that we customize the predictorMatrix so that the Time variable is not used to predict the missing values (we use the cumulative hazard function instead) in the Pain variable and subsequently the imputed datasets will be pooled to get a summary estimate. Note that you also have to activate the package survival before you can run the coxph function in R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the dataset</span>
<span class="kw">library</span>(survival)
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 Survival Missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Compute the cumulative hazard, attach it to the dataset</span>
<span class="co"># and omit the ID variable (first column)</span>
Hazard &lt;-<span class="st"> </span><span class="kw">nelsonaalen</span>(dataset, Time, Status)
dataset &lt;-<span class="st"> </span><span class="kw">data.frame</span>(dataset, Hazard)

<span class="co"># Adapt the PredictorMatrix so that the</span>
<span class="co"># Time variable is not included in the imputation model</span>
Cox.imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">1</span>, <span class="dt">maxit=</span><span class="dv">0</span>, <span class="dt">seed=</span><span class="dv">2795</span>, <span class="dt">printFlag=</span>F)
Pred &lt;-<span class="st"> </span>Cox.imp<span class="op">$</span>predictorMatrix
Pred[<span class="dv">2</span>, <span class="st">&quot;Time&quot;</span>] &lt;-<span class="st"> </span><span class="dv">0</span>
Pred</code></pre></div>
<pre><code>##            Time Status Pain Tampascale Function Radiation Hazard
## Time          0      1    1          1        1         1      1
## Status        0      0    1          1        1         1      1
## Pain          1      1    0          1        1         1      1
## Tampascale    1      1    1          0        1         1      1
## Function      1      1    1          1        0         1      1
## Radiation     1      1    1          1        1         0      1
## Hazard        1      1    1          1        1         1      0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Start imputations using mice</span>
Cox.imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">predictorMatrix=</span>Pred, <span class="dt">seed=</span><span class="dv">2795</span>, <span class="dt">printFlag=</span>F)

fit.Cox &lt;-<span class="st"> </span><span class="kw">with</span>(<span class="dt">data=</span>Cox.imp, <span class="dt">exp=</span><span class="kw">coxph</span>(<span class="kw">Surv</span>(Time, Status) <span class="op">~</span><span class="st"> </span>Pain))
Cox.pool &lt;-<span class="st"> </span><span class="kw">pool</span>(fit.Cox)</code></pre></div>
<pre><code>## Warning: Unknown or uninitialised column: &#39;df.residual&#39;.</code></pre>
<pre><code>## Warning in pool.fitlist(getfit(object), dfcom = dfcom): Large sample
## assumed.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(Cox.pool)</code></pre></div>
<pre><code>##        estimate  std.error statistic       df      p.value
## Pain -0.2021694 0.04789423 -4.221165 36823.71 2.436252e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#   Results of the pooled procedure, with:</span>
<span class="co">#   est: Pooled regression coefficient.</span>
<span class="co">#   se: Standard error of pooled regression coefficient.</span>
<span class="co">#   t: T-value.</span>
<span class="co">#   df: Degrees of freedom.</span>
<span class="co">#   Pr(&gt;|t|): P-value.</span>
<span class="co">#   lo 95 and hi 95: 95% lower and upper confidence intervals.</span>
<span class="co">#   nmis: number of missing observations.</span>
<span class="co">#   fmi: fraction of missing information.</span>
<span class="co">#   Lambda: Proportion of the variation attributable to the missing data </span></code></pre></div>
<p>The value of 0.3319019 in the column named fmi for the Pain variable is calculated according to the Formula 5.17 for FMI. The value 0.2811114 under the column named lambda is calculated according to Formula 5.13.</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="part-iv-data-analysis-after-multiple-imputation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="more-topics-on-multiple-imputation-and-regression-modelling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Book_MI.pdf", "Book_MI.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
