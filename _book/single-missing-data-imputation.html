<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Applied Missing data analysis with SPSS and R(Studio)</title>
  <meta name="description" content="Applied Missing data analysis with SPSS and R(Studio)">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Applied Missing data analysis with SPSS and R(Studio)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Applied Missing data analysis with SPSS and R(Studio)" />
  
  
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Martijn Heymans and Iris Eekhout">


<meta name="date" content="2019-01-16">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="missing-data-evaluation.html">
<link rel="next" href="more-topics-on-multiple-imputation-and-regression-modelling.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Foreword</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#software"><i class="fa fa-check"></i><b>0.1</b> Software</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#notation-in-this-book"><i class="fa fa-check"></i><b>0.2</b> Notation in this book</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#acknowledgement"><i class="fa fa-check"></i><b>0.3</b> Acknowledgement</a></li>
</ul></li>
<li class="part"><span><b>I Part I: Software</b></span></li>
<li class="chapter" data-level="1" data-path="software-applications.html"><a href="software-applications.html"><i class="fa fa-check"></i><b>1</b> Software applications</a><ul>
<li class="chapter" data-level="1.1" data-path="software-applications.html"><a href="software-applications.html#spss"><i class="fa fa-check"></i><b>1.1</b> SPSS</a><ul>
<li class="chapter" data-level="1.1.1" data-path="software-applications.html"><a href="software-applications.html#data-and-variable-view-windows"><i class="fa fa-check"></i><b>1.1.1</b> Data and Variable View windows</a></li>
<li class="chapter" data-level="1.1.2" data-path="software-applications.html"><a href="software-applications.html#analyzing-data-in-spss"><i class="fa fa-check"></i><b>1.1.2</b> Analyzing data in SPSS</a></li>
<li class="chapter" data-level="1.1.3" data-path="software-applications.html"><a href="software-applications.html#the-output-window-in-spss"><i class="fa fa-check"></i><b>1.1.3</b> The Output window in SPSS</a></li>
<li class="chapter" data-level="1.1.4" data-path="software-applications.html"><a href="software-applications.html#the-syntax-editor-in-spss"><i class="fa fa-check"></i><b>1.1.4</b> The Syntax Editor in SPSS</a></li>
<li class="chapter" data-level="1.1.5" data-path="software-applications.html"><a href="software-applications.html#reading-and-saving-data-in-spss"><i class="fa fa-check"></i><b>1.1.5</b> Reading and saving data in SPSS</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="software-applications.html"><a href="software-applications.html#r-and-rstudio"><i class="fa fa-check"></i><b>1.2</b> R and RStudio</a><ul>
<li class="chapter" data-level="1.2.1" data-path="software-applications.html"><a href="software-applications.html#the-role-of-the-console-window"><i class="fa fa-check"></i><b>1.2.1</b> The role of the Console Window</a></li>
<li class="chapter" data-level="1.2.2" data-path="software-applications.html"><a href="software-applications.html#r-assignments-and-objects"><i class="fa fa-check"></i><b>1.2.2</b> R assignments and objects</a></li>
<li class="chapter" data-level="1.2.3" data-path="software-applications.html"><a href="software-applications.html#vectors-matrices-lists-and-data-frames"><i class="fa fa-check"></i><b>1.2.3</b> Vectors, matrices, lists and data frames</a></li>
<li class="chapter" data-level="1.2.4" data-path="software-applications.html"><a href="software-applications.html#indexing-vectors-matrices-lists-and-data-frames"><i class="fa fa-check"></i><b>1.2.4</b> Indexing Vectors, Matrices, Lists and Data frames</a></li>
<li class="chapter" data-level="1.2.5" data-path="software-applications.html"><a href="software-applications.html#vectorized-calculation"><i class="fa fa-check"></i><b>1.2.5</b> Vectorized Calculation</a></li>
<li class="chapter" data-level="1.2.6" data-path="software-applications.html"><a href="software-applications.html#r-functions"><i class="fa fa-check"></i><b>1.2.6</b> R Functions</a></li>
<li class="chapter" data-level="1.2.7" data-path="software-applications.html"><a href="software-applications.html#the-help-function"><i class="fa fa-check"></i><b>1.2.7</b> The Help function</a></li>
<li class="chapter" data-level="1.2.8" data-path="software-applications.html"><a href="software-applications.html#working-with-script-files"><i class="fa fa-check"></i><b>1.2.8</b> Working with script files</a></li>
<li class="chapter" data-level="1.2.9" data-path="software-applications.html"><a href="software-applications.html#creating-a-working-directory"><i class="fa fa-check"></i><b>1.2.9</b> Creating a working directory</a></li>
<li class="chapter" data-level="1.2.10" data-path="software-applications.html"><a href="software-applications.html#reading-in-spss-data-in-rstudio"><i class="fa fa-check"></i><b>1.2.10</b> Reading in SPSS data in RStudio</a></li>
<li class="chapter" data-level="1.2.11" data-path="software-applications.html"><a href="software-applications.html#saving-and-reading-r-data-in-rstudio"><i class="fa fa-check"></i><b>1.2.11</b> Saving and Reading R data in RStudio</a></li>
<li class="chapter" data-level="1.2.12" data-path="software-applications.html"><a href="software-applications.html#reading-in-rstudio-data-into-spss"><i class="fa fa-check"></i><b>1.2.12</b> Reading in (R)Studio data into SPSS</a></li>
<li class="chapter" data-level="1.2.13" data-path="software-applications.html"><a href="software-applications.html#installing-r-packages"><i class="fa fa-check"></i><b>1.2.13</b> Installing R Packages</a></li>
<li class="chapter" data-level="1.2.14" data-path="software-applications.html"><a href="software-applications.html#loading-r-packages"><i class="fa fa-check"></i><b>1.2.14</b> Loading R Packages</a></li>
<li class="chapter" data-level="1.2.15" data-path="software-applications.html"><a href="software-applications.html#updating-r-packages"><i class="fa fa-check"></i><b>1.2.15</b> Updating R Packages</a></li>
<li class="chapter" data-level="1.2.16" data-path="software-applications.html"><a href="software-applications.html#useful-missing-data-packages-and-links"><i class="fa fa-check"></i><b>1.2.16</b> Useful Missing data Packages and links</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Part II: Basic Missing Data Handling</b></span></li>
<li class="chapter" data-level="2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html"><i class="fa fa-check"></i><b>2</b> Missing Data Evaluation</a><ul>
<li class="chapter" data-level="2.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#definition-of-missing-data"><i class="fa fa-check"></i><b>2.1</b> Definition of Missing Data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#defining-missing-data-in-spss"><i class="fa fa-check"></i><b>2.1.1</b> Defining Missing Data in SPSS</a></li>
<li class="chapter" data-level="2.1.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#defining-missing-data-in-r"><i class="fa fa-check"></i><b>2.1.2</b> Defining Missing data in R</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-patterns"><i class="fa fa-check"></i><b>2.2</b> Missing data Patterns</a><ul>
<li class="chapter" data-level="2.2.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#exploring-missing-data-patterns-in-spss"><i class="fa fa-check"></i><b>2.2.1</b> Exploring Missing data patterns in SPSS</a></li>
<li class="chapter" data-level="2.2.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#exploring-missing-data-patterns-in-r"><i class="fa fa-check"></i><b>2.2.2</b> Exploring Missing data patterns in R</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-mechanisms"><i class="fa fa-check"></i><b>2.3</b> Missing data Mechanisms</a><ul>
<li class="chapter" data-level="2.3.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-completely-at-random"><i class="fa fa-check"></i><b>2.3.1</b> Missing Completely At Random</a></li>
<li class="chapter" data-level="2.3.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-at-random"><i class="fa fa-check"></i><b>2.3.2</b> Missing At Random</a></li>
<li class="chapter" data-level="2.3.3" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-not-at-random"><i class="fa fa-check"></i><b>2.3.3</b> Missing Not At Random</a></li>
<li class="chapter" data-level="2.3.4" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#the-missing-data-indicator"><i class="fa fa-check"></i><b>2.3.4</b> The Missing Data Indicator</a></li>
<li class="chapter" data-level="2.3.5" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#the-role-of-auxiliary-variables"><i class="fa fa-check"></i><b>2.3.5</b> The Role of Auxiliary Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-evaluation-1"><i class="fa fa-check"></i><b>2.4</b> Missing Data evaluation</a><ul>
<li class="chapter" data-level="2.4.1" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-evaluation-in-spss"><i class="fa fa-check"></i><b>2.4.1</b> Missing data Evaluation in SPSS</a></li>
<li class="chapter" data-level="2.4.2" data-path="missing-data-evaluation.html"><a href="missing-data-evaluation.html#missing-data-evaluation-in-r"><i class="fa fa-check"></i><b>2.4.2</b> Missing data Evaluation in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html"><i class="fa fa-check"></i><b>3</b> Single Missing data imputation</a><ul>
<li class="chapter" data-level="3.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#complete-cases-analysis"><i class="fa fa-check"></i><b>3.1</b> Complete cases analysis</a></li>
<li class="chapter" data-level="3.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#mean-imputation"><i class="fa fa-check"></i><b>3.2</b> Mean Imputation</a><ul>
<li class="chapter" data-level="3.2.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#mean-imputation-in-spss"><i class="fa fa-check"></i><b>3.2.1</b> Mean imputation in SPSS</a></li>
<li class="chapter" data-level="3.2.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#mean-imputation-in-r"><i class="fa fa-check"></i><b>3.2.2</b> Mean imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#regression-imputation"><i class="fa fa-check"></i><b>3.3</b> Regression imputation</a><ul>
<li class="chapter" data-level="3.3.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#regression-imputation-in-spss"><i class="fa fa-check"></i><b>3.3.1</b> Regression imputation in SPSS</a></li>
<li class="chapter" data-level="3.3.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#regression-imputation-in-r"><i class="fa fa-check"></i><b>3.3.2</b> Regression imputation in R</a></li>
<li class="chapter" data-level="3.3.3" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#stochastic-regression-imputation"><i class="fa fa-check"></i><b>3.3.3</b> Stochastic regression imputation</a></li>
<li class="chapter" data-level="3.3.4" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#stochastic-regression-imputation-in-r"><i class="fa fa-check"></i><b>3.3.4</b> Stochastic regression imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#bayesian-stochastic-regression-imputation"><i class="fa fa-check"></i><b>3.4</b> Bayesian Stochastic regression imputation</a><ul>
<li class="chapter" data-level="3.4.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#bayesian-stochastic-regression-imputation-in-spss"><i class="fa fa-check"></i><b>3.4.1</b> Bayesian Stochastic regression imputation in SPSS</a></li>
<li class="chapter" data-level="3.4.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#bayesian-stochastic-regression-imputation-in-r"><i class="fa fa-check"></i><b>3.4.2</b> Bayesian Stochastic regression imputation in R</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Part III: Multiple Imputation</b></span><ul>
<li class="chapter" data-level="3.5" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#multivariate-imputation-by-chained-equations"><i class="fa fa-check"></i><b>3.5</b> Multivariate Imputation by Chained Equations</a><ul>
<li class="chapter" data-level="3.5.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#the-mice-algorithm-and-iteration-steps"><i class="fa fa-check"></i><b>3.5.1</b> The mice algorithm and iteration steps</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#multiple-imputation-in-r"><i class="fa fa-check"></i><b>3.6</b> Multiple Imputation in R</a><ul>
<li class="chapter" data-level="3.6.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#customizing-the-imputation-model"><i class="fa fa-check"></i><b>3.6.1</b> Customizing the Imputation model</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#output-of-the-mice-function"><i class="fa fa-check"></i><b>3.7</b> Output of the <code>mice</code> function</a><ul>
<li class="chapter" data-level="3.7.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#checking-convergence-in-r"><i class="fa fa-check"></i><b>3.7.1</b> Checking Convergence in R</a></li>
<li class="chapter" data-level="3.7.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#imputation-diagnostics-in-r"><i class="fa fa-check"></i><b>3.7.2</b> Imputation diagnostics in R</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#multiple-imputation-in-spss"><i class="fa fa-check"></i><b>3.8</b> Multiple imputation in SPSS</a><ul>
<li class="chapter" data-level="3.8.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#multiple-imputation-in-spss-1"><i class="fa fa-check"></i><b>3.8.1</b> Multiple imputation in SPSS</a></li>
<li class="chapter" data-level="3.8.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#the-output-for-multiple-imputation-in-spss"><i class="fa fa-check"></i><b>3.8.2</b> The output for Multiple imputation in SPSS</a></li>
<li class="chapter" data-level="3.8.3" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#checking-convergence-after-multiple-imputation-in-spss"><i class="fa fa-check"></i><b>3.8.3</b> Checking Convergence after Multiple imputation in SPSS</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#number-of-imputed-datasets-and-iterations"><i class="fa fa-check"></i><b>3.9</b> Number of Imputed datasets and iterations</a></li>
</ul></li>
<li class="part"><span><b>IV Part IV: Data Analysis After Multiple Imputation</b></span><ul>
<li class="chapter" data-level="3.10" data-path="03-SingleMissingdataimputation.html"><a href="#pooling-results-after-mi-in-spss"><i class="fa fa-check"></i><b>3.10</b> Pooling results after MI in SPSS</a><ul>
<li class="chapter" data-level="3.10.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#imputed-values-are-yellow"><i class="fa fa-check"></i><b>3.10.1</b> Imputed values are yellow</a></li>
<li class="chapter" data-level="3.10.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#the-imputation_-variable"><i class="fa fa-check"></i><b>3.10.2</b> The Imputation_ variable</a></li>
<li class="chapter" data-level="3.10.3" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#special-pooling-icon"><i class="fa fa-check"></i><b>3.10.3</b> Special pooling icon</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-results-after-mi-in-r"><i class="fa fa-check"></i><b>3.11</b> Pooling results after MI in R</a></li>
<li class="chapter" data-level="3.12" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-means-and-standard-deviations-in-spss"><i class="fa fa-check"></i><b>3.12</b> Pooling Means and Standard deviations in SPSS</a></li>
<li class="chapter" data-level="3.13" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-means-and-standard-deviations-in-r"><i class="fa fa-check"></i><b>3.13</b> Pooling Means and Standard Deviations in R</a></li>
<li class="chapter" data-level="3.14" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-correlation-coefficients"><i class="fa fa-check"></i><b>3.14</b> Pooling Correlation coefficients</a><ul>
<li class="chapter" data-level="3.14.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-correlation-coefficients-in-spss"><i class="fa fa-check"></i><b>3.14.1</b> Pooling Correlation coefficients in SPSS</a></li>
<li class="chapter" data-level="3.14.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-correlation-coefficients-in-r"><i class="fa fa-check"></i><b>3.14.2</b> Pooling Correlation Coefficients in R</a></li>
</ul></li>
<li class="chapter" data-level="3.15" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#the-pooled-independent-t-test"><i class="fa fa-check"></i><b>3.15</b> The Pooled Independent T-test</a><ul>
<li class="chapter" data-level="3.15.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-independent-t-tests-in-spss"><i class="fa fa-check"></i><b>3.15.1</b> Pooling Independent T-tests in SPSS</a></li>
<li class="chapter" data-level="3.15.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-independent-t-tests-in-r-with-mice"><i class="fa fa-check"></i><b>3.15.2</b> Pooling Independent T-tests in R with mice</a></li>
<li class="chapter" data-level="3.15.3" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-independent-t-tests-in-r-with-mi.t.test"><i class="fa fa-check"></i><b>3.15.3</b> Pooling Independent T-tests in R with mi.t.test</a></li>
</ul></li>
<li class="chapter" data-level="3.16" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-chi-square-tests"><i class="fa fa-check"></i><b>3.16</b> Pooling Chi-square tests</a><ul>
<li class="chapter" data-level="3.16.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-chi-square-tests-in-spss"><i class="fa fa-check"></i><b>3.16.1</b> Pooling Chi-square tests in SPSS</a></li>
<li class="chapter" data-level="3.16.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-chi-square-tests-in-r"><i class="fa fa-check"></i><b>3.16.2</b> Pooling Chi-square tests in R</a></li>
</ul></li>
<li class="chapter" data-level="3.17" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#analysis-of-variance-anova-pooling"><i class="fa fa-check"></i><b>3.17</b> Analysis of Variance (ANOVA) pooling</a><ul>
<li class="chapter" data-level="3.17.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#analysis-of-variance-anova-pooling-in-spss"><i class="fa fa-check"></i><b>3.17.1</b> Analysis of Variance (ANOVA) pooling in SPSS</a></li>
<li class="chapter" data-level="3.17.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#analysis-of-variance-anova-pooling-in-r"><i class="fa fa-check"></i><b>3.17.2</b> Analysis of Variance (ANOVA) pooling in R</a></li>
</ul></li>
<li class="chapter" data-level="3.18" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-regression-models"><i class="fa fa-check"></i><b>3.18</b> Pooling Regression models</a><ul>
<li class="chapter" data-level="3.18.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-linear-regression-models-in-spss"><i class="fa fa-check"></i><b>3.18.1</b> Pooling Linear Regression Models in SPSS</a></li>
<li class="chapter" data-level="3.18.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-linear-regression-models-in-r"><i class="fa fa-check"></i><b>3.18.2</b> Pooling Linear regression models in R</a></li>
<li class="chapter" data-level="3.18.3" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-logistic-regression-models-in-spss"><i class="fa fa-check"></i><b>3.18.3</b> Pooling Logistic Regression models in SPSS</a></li>
<li class="chapter" data-level="3.18.4" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-logistic-regression-models-in-r"><i class="fa fa-check"></i><b>3.18.4</b> Pooling Logistic Regression models in R</a></li>
</ul></li>
<li class="chapter" data-level="3.19" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-logistic-regression-models-including-categorical-independent-variables"><i class="fa fa-check"></i><b>3.19</b> Pooling logistic regression models including categorical independent variables</a><ul>
<li class="chapter" data-level="3.19.1" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-cox-regression-models"><i class="fa fa-check"></i><b>3.19.1</b> Pooling Cox regression models</a></li>
<li class="chapter" data-level="3.19.2" data-path="single-missing-data-imputation.html"><a href="single-missing-data-imputation.html#pooling-cox-regression-models-in-spss"><i class="fa fa-check"></i><b>3.19.2</b> Pooling Cox regression models in SPSS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="more-topics-on-multiple-imputation-and-regression-modelling.html"><a href="more-topics-on-multiple-imputation-and-regression-modelling.html"><i class="fa fa-check"></i><b>4</b> More topics on Multiple Imputation and Regression Modelling</a></li>
<li class="chapter" data-level="5" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html"><i class="fa fa-check"></i><b>5</b> Multiple Imputation and Regression Modelling</a><ul>
<li class="chapter" data-level="5.1" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#imputing-the-outcome-variable"><i class="fa fa-check"></i><b>5.1</b> Imputing the Outcome variable</a></li>
<li class="chapter" data-level="5.2" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#logistic-regression-with-a-categorical-covariate-in-spss"><i class="fa fa-check"></i><b>5.2</b> Logistic regression with a categorical covariate in SPSS</a></li>
<li class="chapter" data-level="5.3" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#logistic-regression-with-a-categorical-variable-in-r"><i class="fa fa-check"></i><b>5.3</b> Logistic regression with a categorical variable in R</a><ul>
<li class="chapter" data-level="5.3.1" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#multiple-parameter-wald-test-or-d2-method"><i class="fa fa-check"></i><b>5.3.1</b> Multiple parameter Wald test or D2 method</a></li>
<li class="chapter" data-level="5.3.2" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#the-pooled-sampling-variance-or-d1-method"><i class="fa fa-check"></i><b>5.3.2</b> The pooled sampling variance or D1 method</a></li>
<li class="chapter" data-level="5.3.3" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#meng-and-rubin-pooling"><i class="fa fa-check"></i><b>5.3.3</b> Meng and Rubin pooling</a></li>
<li class="chapter" data-level="5.3.4" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#the-median-p-rule"><i class="fa fa-check"></i><b>5.3.4</b> The Median P Rule</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#cox-regression-with-a-categorical-variable-in-r"><i class="fa fa-check"></i><b>5.4</b> Cox Regression with a categorical variable in R</a><ul>
<li class="chapter" data-level="5.4.1" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#multiple-parameter-wald-test-or-d2-method-1"><i class="fa fa-check"></i><b>5.4.1</b> Multiple parameter Wald test or D2 method</a></li>
<li class="chapter" data-level="5.4.2" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#the-pooled-sampling-variance-or-d1-method-1"><i class="fa fa-check"></i><b>5.4.2</b> The pooled sampling variance or D1 method</a></li>
<li class="chapter" data-level="5.4.3" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#the-median-p-rule-1"><i class="fa fa-check"></i><b>5.4.3</b> The Median P Rule</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#predictor-selection"><i class="fa fa-check"></i><b>5.5</b> Predictor selection</a><ul>
<li class="chapter" data-level="5.5.1" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#predictor-selection-functions-in-r"><i class="fa fa-check"></i><b>5.5.1</b> Predictor Selection functions in R</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#interaction-terms-in-model"><i class="fa fa-check"></i><b>5.6</b> Interaction terms in model</a><ul>
<li class="chapter" data-level="5.6.1" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#imputation-of-interaction-terms-in-spss"><i class="fa fa-check"></i><b>5.6.1</b> Imputation of interaction terms in SPSS</a></li>
<li class="chapter" data-level="5.6.2" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#imputation-of-interaction-terms-in-r"><i class="fa fa-check"></i><b>5.6.2</b> Imputation of interaction terms in R</a></li>
<li class="chapter" data-level="5.6.3" data-path="multiple-imputation-and-regression-modelling.html"><a href="multiple-imputation-and-regression-modelling.html#comparing-methods"><i class="fa fa-check"></i><b>5.6.3</b> Comparing methods</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V Part V: Advanced Multiple Imputation methods</b></span></li>
<li class="chapter" data-level="6" data-path="multiple-imputation-models-for-multilevel-data.html"><a href="multiple-imputation-models-for-multilevel-data.html"><i class="fa fa-check"></i><b>6</b> Multiple Imputation models for Multilevel data</a></li>
<li class="chapter" data-level="7" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html"><i class="fa fa-check"></i><b>7</b> Advanced Multiple Imputation models for Multilevel data</a><ul>
<li class="chapter" data-level="7.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#characteristics-of-multilevel-data"><i class="fa fa-check"></i><b>7.1</b> Characteristics of Multilevel data</a></li>
<li class="chapter" data-level="7.2" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#multilevel-data---from-wide-to-long"><i class="fa fa-check"></i><b>7.2</b> Multilevel data - from wide to long</a></li>
<li class="chapter" data-level="7.3" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#multilevel-data---from-wide-to-long-1"><i class="fa fa-check"></i><b>7.3</b> Multilevel data - from wide to long</a></li>
<li class="chapter" data-level="7.4" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#multilevel-data---clusters-and-levels"><i class="fa fa-check"></i><b>7.4</b> Multilevel data - Clusters and Levels</a></li>
<li class="chapter" data-level="7.5" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#the-multilevel-model"><i class="fa fa-check"></i><b>7.5</b> The Multilevel model</a></li>
<li class="chapter" data-level="7.6" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#restructuring-datasets-from-wide-to-long-in-spss"><i class="fa fa-check"></i><b>7.6</b> Restructuring datasets from wide to long in SPSS</a><ul>
<li class="chapter" data-level="7.6.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#restructuring-a-dataset-from-wide-to-long-in-r"><i class="fa fa-check"></i><b>7.6.1</b> Restructuring a dataset from wide to long in R</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#missing-data-at-different-levels"><i class="fa fa-check"></i><b>7.7</b> Missing data at different levels</a></li>
<li class="chapter" data-level="7.8" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#multilevel-imputation-models"><i class="fa fa-check"></i><b>7.8</b> Multilevel imputation models</a><ul>
<li class="chapter" data-level="7.8.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#sporadically-and-systematically-missing-data"><i class="fa fa-check"></i><b>7.8.1</b> Sporadically and Systematically missing data</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#one-stage-multilevel-imputation"><i class="fa fa-check"></i><b>7.9</b> One stage Multilevel Imputation</a><ul>
<li class="chapter" data-level="7.9.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#one-stage-multilevel-imputation-in-r"><i class="fa fa-check"></i><b>7.9.1</b> One stage Multilevel Imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#missing-data-at-different-levels-1"><i class="fa fa-check"></i><b>7.10</b> Missing data at different levels</a></li>
<li class="chapter" data-level="7.11" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#multilevel-imputation-models-1"><i class="fa fa-check"></i><b>7.11</b> Multilevel imputation models</a><ul>
<li class="chapter" data-level="7.11.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#sporadically-and-systematically-missing-data-1"><i class="fa fa-check"></i><b>7.11.1</b> Sporadically and Systematically missing data</a></li>
<li class="chapter" data-level="7.11.2" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#one-stage-multilevel-imputation-1"><i class="fa fa-check"></i><b>7.11.2</b> One stage Multilevel Imputation</a></li>
<li class="chapter" data-level="7.11.3" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#one-stage-multilevel-imputation-in-r-1"><i class="fa fa-check"></i><b>7.11.3</b> One stage Multilevel Imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#two-stage-multilevel-imputation"><i class="fa fa-check"></i><b>7.12</b> Two stage Multilevel Imputation</a><ul>
<li class="chapter" data-level="7.12.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#two-stage-multilevel-imputation-in-r"><i class="fa fa-check"></i><b>7.12.1</b> Two stage Multilevel Imputation in R</a></li>
</ul></li>
<li class="chapter" data-level="7.13" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#the-micemd-package"><i class="fa fa-check"></i><b>7.13</b> The micemd Package</a></li>
<li class="chapter" data-level="7.14" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-multilevel-models"><i class="fa fa-check"></i><b>7.14</b> Pooling Multilevel models</a><ul>
<li class="chapter" data-level="7.14.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-multilevel-models-in-r"><i class="fa fa-check"></i><b>7.14.1</b> Pooling Multilevel Models in R</a></li>
<li class="chapter" data-level="7.14.2" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-multilevel-models-in-spss"><i class="fa fa-check"></i><b>7.14.2</b> Pooling Multilevel Models in SPSS</a></li>
</ul></li>
<li class="chapter" data-level="7.15" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-gee-models"><i class="fa fa-check"></i><b>7.15</b> Pooling GEE models</a><ul>
<li class="chapter" data-level="7.15.1" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-gee-models-in-r"><i class="fa fa-check"></i><b>7.15.1</b> Pooling GEE Models in R</a></li>
<li class="chapter" data-level="7.15.2" data-path="advanced-multiple-imputation-models-for-multilevel-data.html"><a href="advanced-multiple-imputation-models-for-multilevel-data.html#pooling-gee-models-in-spss"><i class="fa fa-check"></i><b>7.15.2</b> Pooling GEE Models in SPSS</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VI Part VI: Missing Data in Questionnaires</b></span></li>
<li class="chapter" data-level="8" data-path="missing-data-in-questionnaires.html"><a href="missing-data-in-questionnaires.html"><i class="fa fa-check"></i><b>8</b> Missing data in questionnaires</a><ul>
<li class="chapter" data-level="8.1" data-path="missing-data-in-questionnaires.html"><a href="missing-data-in-questionnaires.html#methods-for-missing-questionnaire-data"><i class="fa fa-check"></i><b>8.1</b> Methods for missing questionnaire data</a><ul>
<li class="chapter" data-level="8.1.1" data-path="missing-data-in-questionnaires.html"><a href="missing-data-in-questionnaires.html#complete-case-analysis"><i class="fa fa-check"></i><b>8.1.1</b> Complete case analysis</a></li>
<li class="chapter" data-level="8.1.2" data-path="missing-data-in-questionnaires.html"><a href="missing-data-in-questionnaires.html#mean-imputation-1"><i class="fa fa-check"></i><b>8.1.2</b> Mean imputation</a></li>
<li class="chapter" data-level="8.1.3" data-path="missing-data-in-questionnaires.html"><a href="missing-data-in-questionnaires.html#stochastic-regression-imputation-1"><i class="fa fa-check"></i><b>8.1.3</b> (Stochastic) regression imputation</a></li>
<li class="chapter" data-level="8.1.4" data-path="missing-data-in-questionnaires.html"><a href="missing-data-in-questionnaires.html#multiple-imputation"><i class="fa fa-check"></i><b>8.1.4</b> Multiple imputation</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="missing-data-in-questionnaires.html"><a href="missing-data-in-questionnaires.html#practical-issues-with-missing-data-in-questionnaires"><i class="fa fa-check"></i><b>8.2</b> Practical issues with missing data in questionnaires</a><ul>
<li class="chapter" data-level="8.2.1" data-path="missing-data-in-questionnaires.html"><a href="missing-data-in-questionnaires.html#parcel-summary-multiple-imputation"><i class="fa fa-check"></i><b>8.2.1</b> Parcel summary multiple imputation</a></li>
<li class="chapter" data-level="8.2.2" data-path="missing-data-in-questionnaires.html"><a href="missing-data-in-questionnaires.html#passive-multiple-imputation"><i class="fa fa-check"></i><b>8.2.2</b> Passive multiple imputation</a></li>
<li class="chapter" data-level="8.2.3" data-path="missing-data-in-questionnaires.html"><a href="missing-data-in-questionnaires.html#passive-multiple-imputation-in-r"><i class="fa fa-check"></i><b>8.2.3</b> Passive multiple imputation in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="background-information-to-multiple-imputation-methods.html"><a href="background-information-to-multiple-imputation-methods.html"><i class="fa fa-check"></i>Background information to Multiple Imputation Methods</a></li>
<li class="chapter" data-level="9" data-path="rubins-rules.html"><a href="rubins-rules.html"><i class="fa fa-check"></i><b>9</b> Rubinâ€™s Rules</a><ul>
<li class="chapter" data-level="9.1" data-path="rubins-rules.html"><a href="rubins-rules.html#pooling-effect-estimates"><i class="fa fa-check"></i><b>9.1</b> Pooling Effect estimates</a></li>
<li class="chapter" data-level="9.2" data-path="rubins-rules.html"><a href="rubins-rules.html#pooling-standard-errors"><i class="fa fa-check"></i><b>9.2</b> Pooling Standard errors</a></li>
<li class="chapter" data-level="9.3" data-path="rubins-rules.html"><a href="rubins-rules.html#significance-testing"><i class="fa fa-check"></i><b>9.3</b> Significance testing</a></li>
<li class="chapter" data-level="9.4" data-path="rubins-rules.html"><a href="rubins-rules.html#degrees-of-freedom-and-p-values"><i class="fa fa-check"></i><b>9.4</b> Degrees of Freedom and P-values</a></li>
<li class="chapter" data-level="9.5" data-path="rubins-rules.html"><a href="rubins-rules.html#confidence-intervals"><i class="fa fa-check"></i><b>9.5</b> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="measures-of-missing-data-information.html"><a href="measures-of-missing-data-information.html"><i class="fa fa-check"></i><b>10</b> Measures of Missing data information</a><ul>
<li class="chapter" data-level="10.1" data-path="measures-of-missing-data-information.html"><a href="measures-of-missing-data-information.html#fraction-of-missing-information---lambda"><i class="fa fa-check"></i><b>10.1</b> Fraction of Missing Information - Lambda</a></li>
<li class="chapter" data-level="10.2" data-path="measures-of-missing-data-information.html"><a href="measures-of-missing-data-information.html#relative-increase-in-variance"><i class="fa fa-check"></i><b>10.2</b> Relative increase in variance</a></li>
<li class="chapter" data-level="10.3" data-path="measures-of-missing-data-information.html"><a href="measures-of-missing-data-information.html#fraction-of-missing-information---fmi"><i class="fa fa-check"></i><b>10.3</b> Fraction of Missing Information - FMI</a></li>
<li class="chapter" data-level="10.4" data-path="measures-of-missing-data-information.html"><a href="measures-of-missing-data-information.html#relative-efficiency"><i class="fa fa-check"></i><b>10.4</b> Relative Efficiency</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pooling-correlation-coefficients-1.html"><a href="pooling-correlation-coefficients-1.html"><i class="fa fa-check"></i><b>11</b> Pooling correlation coefficients</a><ul>
<li class="chapter" data-level="11.1" data-path="pooling-correlation-coefficients-1.html"><a href="pooling-correlation-coefficients-1.html#pooled-wald-test"><i class="fa fa-check"></i><b>11.1</b> Pooled Wald test</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Missing data analysis with SPSS and R(Studio)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="single-missing-data-imputation" class="section level1">
<h1><span class="header-section-number">3</span> Single Missing data imputation</h1>
<p>The topic of this Chapter is to explain how simple missing data methods like complete case analysis, mean and single regression imputation work. These procedures are still very often applied <span class="citation">(Eekhout et al. <a href="#ref-Eekhout2012">2012</a>)</span> but generally not recommended because they decreases statistical power or lead to an incorrect estimation of standard errors when the data is MCAR, MAR and MNAR <span class="citation">(Eekhout et al. <a href="#ref-Eekhout2014">2014</a>; Van Buuren <a href="#ref-VanBuuren2018">2018</a>; C. K. Enders <a href="#ref-enders2010applied">2010</a>)</span>.</p>
<p>We use as an example data from a study about low back pain and we want to study if the Tampa scale variable is a predictor of low back pain. Both variables are continuous. Pain represents the intensity of the low back pain and the Tampa scale measures fear of moving the low back. The Tampa scale variable contains missing values. The number or type of missing values is not important because the main topic is to show how simple missing data methods work in SPSS and R.</p>
<p>To get a first impression about the relationship between the Pain and the Tampa scale variables we make a scatterplot. The scatterplots with the complete and intended incomplete data is displayed in Figure <a href="single-missing-data-imputation.html#fig:fig3-1">3.1</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-1"></span>
<img src="images/fig3.2a.png" alt="Relationship between the Tampa scale and Pain variables (green dots are observed and red dots are the missing data" width="70%" />
<p class="caption">
Figure 3.1: Relationship between the Tampa scale and Pain variables (green dots are observed and red dots are the missing data
</p>
</div>
<p>The green dots in Figure 3.1 represent the observed data and the red dots the missing data points. In practice, you work with the available points that are visualized in Figure <a href="single-missing-data-imputation.html#fig:fig3-2">3.2</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-2"></span>
<img src="images/fig3.2b.png" alt="Relationship between the Tampa scale and Pain variable. Missing data are excluded" width="70%" />
<p class="caption">
Figure 3.2: Relationship between the Tampa scale and Pain variable. Missing data are excluded
</p>
</div>
<div id="complete-cases-analysis" class="section level2">
<h2><span class="header-section-number">3.1</span> Complete cases analysis</h2>
<p>Complete case analysis (CCA) means that persons with a missing data point are excluded from the dataset before statistical analyses are performed. Nevertheless it is the default procedure in many statistical software packages such as SPSS.</p>
</div>
<div id="mean-imputation" class="section level2">
<h2><span class="header-section-number">3.2</span> Mean Imputation</h2>
<p>With mean imputation the mean of a variable that contains missing values is calculated and used to replace all missing values in that variable.</p>
<div id="mean-imputation-in-spss" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Mean imputation in SPSS</h3>
<p><em>Descriptive Statistics</em></p>
<p>The easiest method to do mean imputation is by calculating the mean using</p>
<blockquote>
<p>Analyze -&gt; Descriptive Statistics -&gt; Descriptives</p>
</blockquote>
<p>and than replace the missing values by the mean value by using the â€œRecode into Same Variablesâ€under the Transform menu.</p>
<p>Other procedures for mean imputation are the <em>Replace Missing Values</em> procedure under Transform and by using the <em>Linear Regression</em> procedure.</p>
<p><em>Replace Missing Values procedure</em></p>
<p>You can find the Replace Missing Values dialog box via</p>
<blockquote>
<p>Transform -&gt; Replace Missing Values.</p>
</blockquote>
<p>A new window opens. Transport the Tampa scale variable to the New variable(s) window (Figure <a href="single-missing-data-imputation.html#fig:fig3-3">3.3</a>). The default imputation procedure is Mean imputation or called â€œSeries meanâ€.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-3"></span>
<img src="images/fig3.6.png" alt="Window for mean imputation of the Tampa scale variable." width="70%" />
<p class="caption">
Figure 3.3: Window for mean imputation of the Tampa scale variable.
</p>
</div>
<p>When you click on OK, a new variable is created in the dataset using the existing variable name followed by an underscore and a sequential number. The result is shown in Figure <a href="single-missing-data-imputation.html#fig:fig3-7">3.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-7"></span>
<img src="images/fig3.7.png" alt="Mean imputation of the Tampa scale variable with the Replace Missing Values procedure." width="70%" />
<p class="caption">
Figure 3.4: Mean imputation of the Tampa scale variable with the Replace Missing Values procedure.
</p>
</div>
<p>If we now make the scatterplot between the Pain and the Tampa scale variable it clearly shows the result of the mean imputation procedure, all imputed values are located at the mean value (Figure <a href="single-missing-data-imputation.html#fig:fig3-4">3.5</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-4"></span>
<img src="images/fig3.4.png" alt="Scatterplot between the Tampa scale and Pain variable, after the missing values of the Tampa scale variable have been replaced by the mean." width="70%" />
<p class="caption">
Figure 3.5: Scatterplot between the Tampa scale and Pain variable, after the missing values of the Tampa scale variable have been replaced by the mean.
</p>
</div>
<p><em>Linear Regression</em></p>
<p>Mean imputation is also integrated in the Linear Regression menu via:</p>
<blockquote>
<p>Analyze -&gt; Regression -&gt; Linear -&gt; Options.</p>
</blockquote>
<p>In the Missing Values group you choose for Replace with mean (Figure <a href="single-missing-data-imputation.html#fig:fig3-8">3.6</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-8"></span>
<img src="images/fig3.8.png" alt="The option Replace with mean in the Linear Regression menu." width="70%" />
<p class="caption">
Figure 3.6: The option Replace with mean in the Linear Regression menu.
</p>
</div>
</div>
<div id="mean-imputation-in-r" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Mean imputation in R</h3>
<p>You can do mean imputation by using the mice function in the mice package and choose as method â€œmeanâ€.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(foreign) <span class="co"># activate the foreign package to use the read.spss function</span>
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;data/Backpain 50 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mice) <span class="co"># Activate the mice package to use the mice function</span>
imp_mean &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">method=</span><span class="st">&quot;mean&quot;</span>, <span class="dt">m=</span><span class="dv">1</span>, <span class="dt">maxit=</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## 
##  iter imp variable
##   1   1  Tampascale</code></pre>
<p>You can extract the mean imputed dataset by using the complete function as follows: <code>complete(imp_mean)</code></p>
</div>
</div>
<div id="regression-imputation" class="section level2">
<h2><span class="header-section-number">3.3</span> Regression imputation</h2>
<p>With regression imputation the information of other variables is used to predict the missing values in a variable by using a regression model. Commonly, first the regression model is estimated in the observed data and subsequently using the regression weights the missing values are predicted and replaced.</p>
<div id="regression-imputation-in-spss" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Regression imputation in SPSS</h3>
<p>You can apply regression imputation in SPSS via the Missing Value Analysis menu. There are two options for regression imputation, the Regression option and the Expectation Maximization (EM) option. The Regression option in SPSS has some flaws in the estimation of the regression parameters <span class="citation">(Hippel <a href="#ref-hippel2004">2004</a>)</span>. Therefore, we recommend the EM algorithm. This algorithm is a likelihood-based procedure. This means that the most likely values of the regression coefficients are estimated given the data and subsequently used to impute the missing value. This EM procedure gives the same results as first performing a simple regression analysis in the dataset and subsequently estimate the missing values from the regression equation. Both methods are described below.</p>
<div id="em-procedure" class="section level4">
<h4><span class="header-section-number">3.3.1.1</span> EM procedure</h4>
<p>Step 1, go to:</p>
<blockquote>
<p>Analyze -&gt; Missing Value Analysisâ€¦</p>
</blockquote>
<p>In the main Missing Value Analysis dialog box, select the variable(s) and select EM in the Estimation group (Figure <a href="single-missing-data-imputation.html#fig:fig3-10">3.7</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-10"></span>
<img src="images/fig3.10.png" alt="EM Selection in the Missing Value Analysis window." width="70%" />
<p class="caption">
Figure 3.7: EM Selection in the Missing Value Analysis window.
</p>
</div>
<p>Step 2 click Variables, to specify predicted and predictor variables. Place the Tampascale variable in the Predicted variables window and the Pain variable in the Predictor Variables window (Figure <a href="single-missing-data-imputation.html#fig:fig3-11">3.8</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-11"></span>
<img src="images/fig3.11.png" alt="Transfer of the Tampascale and Pain variables to the Predicted and Predictor Variables windows." width="70%" />
<p class="caption">
Figure 3.8: Transfer of the Tampascale and Pain variables to the Predicted and Predictor Variables windows.
</p>
</div>
<p>Step 3 Click on Continue -&gt; EM and select Normal in the Distribution group. Than thick Save completed data and give the dataset a name, for example â€œImpTampa_EMâ€ (Figure <a href="single-missing-data-imputation.html#fig:fig3-12">3.9</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-12"></span>
<img src="images/fig3.12.png" alt="Name of dataset to save the EM results in." width="70%" />
<p class="caption">
Figure 3.9: Name of dataset to save the EM results in.
</p>
</div>
<p>Step 4 Click Continue -&gt; OK. The new dataset â€œImpTampa_EMâ€ will open in a new window in SPSS. In this dataset the imputed data for the Tampascale Variable together with the original data is stored (Figure <a href="single-missing-data-imputation.html#fig:fig3-13">3.10</a>, first 15 patients are shown).</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-13"></span>
<img src="images/fig3.13.png" alt="Result of the EM procedure." width="70%" />
<p class="caption">
Figure 3.10: Result of the EM procedure.
</p>
</div>
<p>BNote that SPSS uses as default only quantitative variables to impute the missing values with the EM algorithm.</p>
</div>
<div id="normal-linear-regression-imputation" class="section level4">
<h4><span class="header-section-number">3.3.1.2</span> Normal Linear Regression imputation</h4>
<p>We first estimate the relationship between Pain and the Tampa scale variable in the dataset with linear regression, by default subjects with missing values are excluded. Subsequently, we use the regression coefficients from this regression model to estimate the imputed values in the Tampa scale variable.</p>
<p>To estimate the linear regression model, choose:</p>
<blockquote>
<p>Analyze -&gt; Regression -&gt; Linear</p>
</blockquote>
<p>Transfer the Tampa scale variable to the Dependent variable box and the Pain variable to the â€œIndependent(s) in the Block 1 of 1 group. Then click OK.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-14"></span>
<img src="images/fig3.14.png" alt="Linear regression analysis with the Tampa scale as the outcome and Pain as the independent variable." width="70%" />
<p class="caption">
Figure 3.11: Linear regression analysis with the Tampa scale as the outcome and Pain as the independent variable.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:tab3-3"></span>
<img src="images/table3.3.png" alt="Result of the linear regression analysis." width="70%" />
<p class="caption">
Figure 3.12: Result of the linear regression analysis.
</p>
</div>
<p>The linear regression model can be described as:</p>
<p><span class="math display">\[Tampascale = 32.005 + 1.410 Ã— Pain\]</span></p>
<p>Now impute the missing values in the Tampa scale variable and compare them with the EM estimates. You see that the results are the same.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-15"></span>
<img src="images/fig3.15.png" alt="Predictions of the missing Tampa scale values on basis of the regression model estimated in the dataset after the missing values were excluded." width="70%" />
<p class="caption">
Figure 3.13: Predictions of the missing Tampa scale values on basis of the regression model estimated in the dataset after the missing values were excluded.
</p>
</div>
<p>In the scatterplot of the imputations from the regression model you see that, as expected, the imputed values are directly on the regression line (Figure <a href="single-missing-data-imputation.html#fig:fig3-16">3.14</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-16"></span>
<img src="images/fig3.16.png" alt="Relationship between the Tampa scale and the Pain variable." width="70%" />
<p class="caption">
Figure 3.14: Relationship between the Tampa scale and the Pain variable.
</p>
</div>
</div>
</div>
<div id="regression-imputation-in-r" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Regression imputation in R</h3>
<p>You can aply regression imputation in R with as method setting â€œnorm.predictâ€ in the mice function. The Pain variable is used to predict the missing values in the Tampa scale variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(foreign)
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;data/Backpain 50 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span>dataset[, <span class="kw">c</span>(<span class="st">&quot;Pain&quot;</span>, <span class="st">&quot;Tampascale&quot;</span>)]

imp.regress &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">method=</span><span class="st">&quot;norm.predict&quot;</span>, <span class="dt">m=</span><span class="dv">1</span>, <span class="dt">maxit=</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## 
##  iter imp variable
##   1   1  Tampascale</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp.regress<span class="op">$</span>imp<span class="op">$</span>Tampascale <span class="co"># Extract the imputed values</span></code></pre></div>
<pre><code>##           1
## 2  40.46554
## 6  41.87566
## 9  34.82506
## 14 40.46554
## 21 39.05542
## 25 39.05542
## 27 44.69590
## 31 46.10602
## 35 40.46554
## 37 43.28578
## 44 33.41494
## 49 34.82506
## 50 43.28578</code></pre>
<p>Expectantly, this gives comparable results as the regression imputation to SPSS above. The method â€œnorm.predictâ€ in the mice package fits a linear regression model in the dataset and generates the imputed values for the Tampa scale variable by using the regression coefficients of the linear regression model. The completed dataset can be extracted by using the complete function in the mice package.</p>
</div>
<div id="stochastic-regression-imputation" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Stochastic regression imputation</h3>
<p>In Stochastic regression models imputation uncertainty is accounted for by adding extra error variance to the predicted values from the linear regression model. Stochastic regression can be activated in SPSS via the Missing Value Analysis and the Regression Estimation option. However, the Regression Estimation option generates incorrect regression coefficient estimates <span class="citation">(Hippel <a href="#ref-hippel2004">2004</a>)</span> and will therefore not further discussed.</p>
</div>
<div id="stochastic-regression-imputation-in-r" class="section level3">
<h3><span class="header-section-number">3.3.4</span> Stochastic regression imputation in R</h3>
<p>You can apply stochastic regression imputation in R with the mice function using the method â€œnorm.nobâ€.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;data/Backpain 50 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span>dataset[, <span class="kw">c</span>(<span class="st">&quot;Pain&quot;</span>, <span class="st">&quot;Tampascale&quot;</span>)]

imp_nob &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">method=</span><span class="st">&quot;norm.nob&quot;</span>, <span class="dt">m=</span><span class="dv">1</span>, <span class="dt">maxit=</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## 
##  iter imp variable
##   1   1  Tampascale</code></pre>
<p>The completed dataset can be extracted by using the complete function in the mice package.</p>
</div>
</div>
<div id="bayesian-stochastic-regression-imputation" class="section level2">
<h2><span class="header-section-number">3.4</span> Bayesian Stochastic regression imputation</h2>
<p>For more information about the theory of Bayesian statistics we refer to the books of <span class="citation">(Box and Tiao <a href="#ref-box2007bayesianinferencein">2007</a>; C. K. Enders <a href="#ref-enders2010applied">2010</a>; Gelman et al. <a href="#ref-gelman2014bayesian">2014</a>)</span>.</p>
<div id="bayesian-stochastic-regression-imputation-in-spss" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Bayesian Stochastic regression imputation in SPSS</h3>
<p>In SPSS Bayesian Stochastic regression imputation can be performed via the multiple imputation menu. To generate imputations for the Tampa scale variable, we use the Pain variable as the only predictor.</p>
<p><strong>Step 1</strong></p>
<p>To start the imputation procedure, Go to</p>
<blockquote>
<p>Analyze -&gt; Multiple Imputation -&gt; Impute Missing Data Values.</p>
</blockquote>
<p>In the first window you define which variables are included in the imputation model. Transfer the Tampa scale and Pain variable to the Variables in Model box. Than set the number of imputed datasets to 1 under Imputations and give the dataset where the imputed values are stored under â€œCreate a new datasetâ€ a name. Here we give it the name â€œImpStoch_Tampaâ€ (Figure <a href="single-missing-data-imputation.html#fig:fig3-18">3.15</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-18"></span>
<img src="images/fig3.18.png" alt="The Variables window." width="70%" />
<p class="caption">
Figure 3.15: The Variables window.
</p>
</div>
<p><strong>Step 2</strong></p>
<p>In the Methods tab, choose under Imputation Method for custom and then Fully conditional specification (MCMC). Set the Maximum iterations number at 50. This specifies the number of iterations as part of the FCS method (Figure <a href="single-missing-data-imputation.html#fig:fig3-19">3.16</a>). We further use the default settings.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-19"></span>
<img src="images/fig3.19.png" alt="The Methods tab." width="70%" />
<p class="caption">
Figure 3.16: The Methods tab.
</p>
</div>
<p><strong>Step 3</strong></p>
<p>In the constraints window (Figure <a href="single-missing-data-imputation.html#fig:fig3-20">3.17</a>) click on the Scan Data button and further use the default settings.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-20"></span>
<img src="images/fig3.20.png" alt="Bayesian Stochastic regression imputation" width="70%" />
<p class="caption">
Figure 3.17: Bayesian Stochastic regression imputation
</p>
</div>
<p><strong>Step 4</strong></p>
<p>In the Output window we only use the default settings.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-21"></span>
<img src="images/fig3.21.png" alt="The Output tab." width="70%" />
<p class="caption">
Figure 3.18: The Output tab.
</p>
</div>
<p><strong>Step 5</strong></p>
<p>Now click on OK button to start the imputation procedure</p>
<p>The output dataset consists of the original data with missing data plus a set of cases with imputed values for each imputation. The imputed datasets are stacked under each other. The file also contains a new variable, Imputation_, which indicates the number of the imputed dataset (0 for original data and more than 0 for the imputed datasets). The variable Imputation_ is added to the dataset and the imputed values are marked yellow.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-22"></span>
<img src="images/fig3.22.png" alt="Imputed dataset." width="70%" />
<p class="caption">
Figure 3.19: Imputed dataset.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig3-23"></span>
<img src="images/fig3.23.png" alt="Imputed dataset with the imputed values marked yellow." width="70%" />
<p class="caption">
Figure 3.20: Imputed dataset with the imputed values marked yellow.
</p>
</div>
<p>When we make a scatterplot of the Pain and the Tampascale variable (Figure <a href="single-missing-data-imputation.html#fig:fig3-24">3.21</a>) we see that there is more variation in the Tampascale variable, or you could say that the variation in the Tampascale variable is â€œrepairedâ€.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-24"></span>
<img src="images/fig3.24.png" alt="Scatterplot of the relationship between Tampascale and the Pain variable, including the imputed values for the Tampascale variable (red dots)." width="70%" />
<p class="caption">
Figure 3.21: Scatterplot of the relationship between Tampascale and the Pain variable, including the imputed values for the Tampascale variable (red dots).
</p>
</div>
<p>The full Multiple Imputation procedure will be discussed in more detail in the next Chapter.</p>
</div>
<div id="bayesian-stochastic-regression-imputation-in-r" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Bayesian Stochastic regression imputation in R</h3>
<p>The package mice also include a Bayesian stochastic regression imputation procedure. You can apply this imputation procedure with the mice function and use as method â€œnormâ€. The pain variable is the only predictor variable for the missing values in the Tampa scale variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;data/Backpain 50 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span>dataset[, <span class="kw">c</span>(<span class="st">&quot;Pain&quot;</span>, <span class="st">&quot;Tampascale&quot;</span>)]

imp_b &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">method=</span><span class="st">&quot;norm&quot;</span>, <span class="dt">m=</span><span class="dv">1</span>, <span class="dt">maxit=</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## 
##  iter imp variable
##   1   1  Tampascale</code></pre>
<p>The completed dataset can be extracted by using the complete function in the mice package.</p>

</div>
</div>
</div>



<div class="figure" style="text-align: center"><span id="fig:fig4-1"></span>
<img src="images/fig4.1_update.png" alt="Graphical presentation of the MI procedure." width="90%" />
<p class="caption">
Figure 3.22: Graphical presentation of the MI procedure.
</p>
</div>
<p>In the first step, the dataset with missing values (i.e.Â the incomplete dataset) is copied several times. Then in the next step, the missing values are replaced with imputed values in each copy of the dataset. In each copy, slightly different values are imputed due to random variation. This results in mulitple imputed datasets. In the third step, the imputed datasets are each analyzed and the study results are then pooled into the final study result. In this Chapter, the first phase in multiple imputation, the imputation step, is the main topic. In the next Chapter, the analysis and pooling phases are discussed.</p>
<p>There are many different algorithms developed to impute missing values with a multiple imptuation procedure. For example multivariate imputation, where all variables are imputed in one iteration under the multivariate normal assumption, or multivariate imputation by chained equations, where variables are imputed sequentially. The latter method will be explained more thorougly in the next paragraph.</p>
<div id="multivariate-imputation-by-chained-equations" class="section level2">
<h2><span class="header-section-number">3.5</span> Multivariate Imputation by Chained Equations</h2>
<p>Multivariate imputation by chained equations (MICE) is also known as Sequential Regression Imputation, Fully Conditional Specification or Gibbs sampling. In the MICE algorithm, a chain of regression equations is used to obtain imputations, which means that variables with missing data are imputed one by one. The regression models use information from all other variables in the model, i.e.Â conditional imputation models. In order to add sampling variability to the imputations, residual error is added to create the imputed values. This residual error can either be added to the prediced values directly, which is esentially similar to repeating stochastic regression imputation over several imputation runs. Or, the residual variance can be added via the parameter estimates of the regression model, which is a Bayesian sampling method. The Bayesian method is the default in the <code>mice</code> package in R.</p>
<div id="the-mice-algorithm-and-iteration-steps" class="section level3">
<h3><span class="header-section-number">3.5.1</span> The mice algorithm and iteration steps</h3>
<p>Each imputed dataset is generated after several iterations of the imputation algorithm. The imputation algorithm includes the chain of regression equations to estimate the imputed values. How this works exactly is explained with the LBP data as an illustration. In this data we have missing values in the Tampa scale variable and the disability variable; the other two variables, radiation and pain, are completely observed.</p>
<p>Per imputed dataset we start with iteration number 0. Data points are randomly drawn from the observed values of the Tampa scale and the Disability variable and these are used to replace the missing values in these variables.</p>
<p>For iteration 1 the Tampa scale values are set back to missing. Subsequently, a linear regression model is applied in the available data (i.e.Â all subjects with observed Tampa scale values) using the Tampa scale as the dependent variable and Pain, Disability and Radiation as independent variables. Note that for this regression the imputed values for disability from the previous iteration are used. The Baysian sampling method then draws regression coefficients from the posterior distribution of the parameters of this regression. The imputed values for Tampa scale are the predicted values from the linear regression. This regression equation is defined as:</p>
<p><span class="math inline">\(Tampa_{mis} = \beta_0 + \beta_1Pain + \beta_2Disability + \beta_3Radiation\)</span></p>
<p>where <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span> and <span class="math inline">\(\beta_3\)</span> are Bayseian sampling draws from their posterior distributions. The same procedure is repeated for the Disability variable. The Disability scores are first set back to missing, then the regression coefficients for the Pain, Tampa scale and Radiation variables are obtained from the subjects without missing diability values. Note that the imputed values for Tampa scale are used. The imputed values for disability are estimated using the regression coefficients with additional random error drawn from the residual error distribution.</p>
<p><span class="math inline">\(Disability_{mis} = \beta_0 + \beta_1Pain + \beta_2Tampa + \beta_3Radiation\)</span></p>
<p>For iteration 2 the Tampa scale values are again set back to missing and (new) updated regression coefficients for Pain, Disability and Radiation are obtained, using the imputed values for Disability from iteration 1. Accordingly, missing values are estimated from regression model where the coefficients are again drawn from the posterior distributions of the estimated parameters. The same holds for the Disability variable. The imputed values for disability are estimated by the regression model using the imputed values in Tampa scale from iteration 2. This process is repeated in each following iteration until the final iteration where the imputed values are used for the first imputed dataset. For the next imputed dataset, the entire process of iterations is repeated.</p>
</div>
</div>
<div id="multiple-imputation-in-r" class="section level2">
<h2><span class="header-section-number">3.6</span> Multiple Imputation in R</h2>
<p>In R multiple imputation can be performed with the <code>mice</code> function from the <code>mice</code> package. The following default settings are used in the <code>mice</code> function to start MI, <code>m=5</code>, to generate 5 imputed datasets, <code>maxit=10</code>, to use 10 iterations for each imputed dataset (i.e.Â 10 chains of regression imputation models), <code>method=â€pmmâ€</code>. For an elobate explanation of all options withing the mice function, see <code>?mice</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mice)
<span class="kw">library</span>(haven)
data &lt;-<span class="st"> </span><span class="kw">read_sav</span>(<span class="st">&quot;data/Backpain 50 missing.sav&quot;</span>)
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(data, <span class="dt">m=</span><span class="dv">5</span>, <span class="dt">maxit=</span><span class="dv">10</span>, <span class="dt">method=</span><span class="st">&quot;pmm&quot;</span>)</code></pre></div>
<pre><code>## 
##  iter imp variable
##   1   1  Tampascale
##   1   2  Tampascale
##   1   3  Tampascale
##   1   4  Tampascale
##   1   5  Tampascale
##   2   1  Tampascale
##   2   2  Tampascale
##   2   3  Tampascale
##   2   4  Tampascale
##   2   5  Tampascale
##   3   1  Tampascale
##   3   2  Tampascale
##   3   3  Tampascale
##   3   4  Tampascale
##   3   5  Tampascale
##   4   1  Tampascale
##   4   2  Tampascale
##   4   3  Tampascale
##   4   4  Tampascale
##   4   5  Tampascale
##   5   1  Tampascale
##   5   2  Tampascale
##   5   3  Tampascale
##   5   4  Tampascale
##   5   5  Tampascale
##   6   1  Tampascale
##   6   2  Tampascale
##   6   3  Tampascale
##   6   4  Tampascale
##   6   5  Tampascale
##   7   1  Tampascale
##   7   2  Tampascale
##   7   3  Tampascale
##   7   4  Tampascale
##   7   5  Tampascale
##   8   1  Tampascale
##   8   2  Tampascale
##   8   3  Tampascale
##   8   4  Tampascale
##   8   5  Tampascale
##   9   1  Tampascale
##   9   2  Tampascale
##   9   3  Tampascale
##   9   4  Tampascale
##   9   5  Tampascale
##   10   1  Tampascale
##   10   2  Tampascale
##   10   3  Tampascale
##   10   4  Tampascale
##   10   5  Tampascale</code></pre>
<p>By default, the mice fucntion returns information about the iteration and imputation steps for the variable that are imputed under the columns named â€œiterâ€, â€œimpâ€ and â€œvariableâ€. This information can be turned off by setting the mice function parameter printFlag = FALSE, which results in silent computation of the missing values. A summary of the imputation results can be obtained by calling the imp object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp</code></pre></div>
<pre><code>## Class: mids
## Number of multiple imputations:  5 
## Imputation methods:
##         ID       Pain Tampascale Disability  Radiation 
##         &quot;&quot;         &quot;&quot;      &quot;pmm&quot;         &quot;&quot;         &quot;&quot; 
## PredictorMatrix:
##            ID Pain Tampascale Disability Radiation
## ID          0    1          1          1         1
## Pain        1    0          1          1         1
## Tampascale  1    1          0          1         1
## Disability  1    1          1          0         1
## Radiation   1    1          1          1         0</code></pre>
<p>This object contains information about the algorithm, the number of imputed datasets, the missing values in each variable, the imputation method, the VisitSequence which is the order in which the variables are imputed during the imputation process, information of the PredictorMatrix and the seed value for the random number generator. The imputed datasets can be extracted by using the complete function. The setting <code>action = 1</code> returns the first imputed dataset. The settings <code>action = â€longâ€</code> and <code>include = TRUE</code> returns a data.frame where the imputed datasets are stacked under each other and include the original dataset (with missings) on top (see ?complete for more possibilities how to store the imputed datasets).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">complete</span>(imp, <span class="dt">action =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>##    ID Pain Tampascale Disability Radiation
## 1   1    9         45         20         1
## 2   2    6         44         10         0
## 3   3    1         36          1         0
## 4   4    5         38         14         0
## 5   5    6         44         14         1
## 6   6    7         40         11         1
## 7   7    8         43         18         0
## 8   8    6         43         11         1
## 9   9    2         31         11         1
## 10 10    4         36          3         0
## 11 11    5         38         16         1
## 12 12    9         47         14         0
## 13 13    0         32          3         1
## 14 14    6         37         12         0
## 15 15    3         34         13         0
## 16 16    6         42          8         1
## 17 17    3         35         11         0
## 18 18    1         31          1         0
## 19 19    2         31          7         0
## 20 20    4         32          9         1
## 21 21    5         37         13         0
## 22 22    5         39         12         0
## 23 23    4         34          8         1
## 24 24    8         47         13         1
## 25 25    5         42          6         0
## 26 26    5         38         16         1
## 27 27    9         45         23         1
## 28 28    3         36          3         1
## 29 29    2         36          9         0
## 30 30    6         37         16         0
## 31 31   10         47         21         1
## 32 32    4         37          8         0
## 33 33   10         42         20         1
## 34 34    2         37          3         0
## 35 35    6         43         12         1
## 36 36    3         38          7         1
## 37 37    8         47          8         0
## 38 38    3         38          6         1
## 39 39    3         39          8         0
## 40 40    7         44         15         0
## 41 41    7         45         10         0
## 42 42    6         40         12         1
## 43 43    7         40         16         1
## 44 44    1         36          2         0
## 45 45    9         41         19         0
## 46 46    5         41         17         0
## 47 47    6         43         11         0
## 48 48    3         39          9         0
## 49 49    2         39          6         1
## 50 50    8         47         19         0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">complete</span>(imp, <span class="dt">action =</span> <span class="st">&quot;long&quot;</span>, <span class="dt">include =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>##     .imp .id ID Pain Tampascale Disability Radiation
## 1      0   1  1    9         45         20         1
## 2      0   2  2    6         NA         10         0
## 3      0   3  3    1         36          1         0
## 4      0   4  4    5         38         14         0
## 5      0   5  5    6         44         14         1
## 6      0   6  6    7         NA         11         1
## 7      0   7  7    8         43         18         0
## 8      0   8  8    6         43         11         1
## 9      0   9  9    2         NA         11         1
## 10     0  10 10    4         36          3         0
## 11     0  11 11    5         38         16         1
## 12     0  12 12    9         47         14         0
## 13     0  13 13    0         32          3         1
## 14     0  14 14    6         NA         12         0
## 15     0  15 15    3         34         13         0
## 16     0  16 16    6         42          8         1
## 17     0  17 17    3         35         11         0
## 18     0  18 18    1         31          1         0
## 19     0  19 19    2         31          7         0
## 20     0  20 20    4         32          9         1
## 21     0  21 21    5         NA         13         0
## 22     0  22 22    5         39         12         0
## 23     0  23 23    4         34          8         1
## 24     0  24 24    8         47         13         1
## 25     0  25 25    5         NA          6         0
## 26     0  26 26    5         38         16         1
## 27     0  27 27    9         NA         23         1
## 28     0  28 28    3         36          3         1
## 29     0  29 29    2         36          9         0
## 30     0  30 30    6         37         16         0
## 31     0  31 31   10         NA         21         1
## 32     0  32 32    4         37          8         0
## 33     0  33 33   10         42         20         1
## 34     0  34 34    2         37          3         0
## 35     0  35 35    6         NA         12         1
## 36     0  36 36    3         38          7         1
## 37     0  37 37    8         NA          8         0
## 38     0  38 38    3         38          6         1
## 39     0  39 39    3         39          8         0
## 40     0  40 40    7         44         15         0
## 41     0  41 41    7         45         10         0
## 42     0  42 42    6         40         12         1
## 43     0  43 43    7         40         16         1
## 44     0  44 44    1         NA          2         0
## 45     0  45 45    9         41         19         0
## 46     0  46 46    5         41         17         0
## 47     0  47 47    6         43         11         0
## 48     0  48 48    3         39          9         0
## 49     0  49 49    2         NA          6         1
## 50     0  50 50    8         NA         19         0
## 51     1   1  1    9         45         20         1
## 52     1   2  2    6         44         10         0
## 53     1   3  3    1         36          1         0
## 54     1   4  4    5         38         14         0
## 55     1   5  5    6         44         14         1
## 56     1   6  6    7         40         11         1
## 57     1   7  7    8         43         18         0
## 58     1   8  8    6         43         11         1
## 59     1   9  9    2         31         11         1
## 60     1  10 10    4         36          3         0
## 61     1  11 11    5         38         16         1
## 62     1  12 12    9         47         14         0
## 63     1  13 13    0         32          3         1
## 64     1  14 14    6         37         12         0
## 65     1  15 15    3         34         13         0
## 66     1  16 16    6         42          8         1
## 67     1  17 17    3         35         11         0
## 68     1  18 18    1         31          1         0
## 69     1  19 19    2         31          7         0
## 70     1  20 20    4         32          9         1
## 71     1  21 21    5         37         13         0
## 72     1  22 22    5         39         12         0
## 73     1  23 23    4         34          8         1
## 74     1  24 24    8         47         13         1
## 75     1  25 25    5         42          6         0
## 76     1  26 26    5         38         16         1
## 77     1  27 27    9         45         23         1
## 78     1  28 28    3         36          3         1
## 79     1  29 29    2         36          9         0
## 80     1  30 30    6         37         16         0
## 81     1  31 31   10         47         21         1
## 82     1  32 32    4         37          8         0
## 83     1  33 33   10         42         20         1
## 84     1  34 34    2         37          3         0
## 85     1  35 35    6         43         12         1
## 86     1  36 36    3         38          7         1
## 87     1  37 37    8         47          8         0
## 88     1  38 38    3         38          6         1
## 89     1  39 39    3         39          8         0
## 90     1  40 40    7         44         15         0
## 91     1  41 41    7         45         10         0
## 92     1  42 42    6         40         12         1
## 93     1  43 43    7         40         16         1
## 94     1  44 44    1         36          2         0
## 95     1  45 45    9         41         19         0
## 96     1  46 46    5         41         17         0
## 97     1  47 47    6         43         11         0
## 98     1  48 48    3         39          9         0
## 99     1  49 49    2         39          6         1
## 100    1  50 50    8         47         19         0
## 101    2   1  1    9         45         20         1
## 102    2   2  2    6         37         10         0
## 103    2   3  3    1         36          1         0
## 104    2   4  4    5         38         14         0
## 105    2   5  5    6         44         14         1
## 106    2   6  6    7         40         11         1
## 107    2   7  7    8         43         18         0
## 108    2   8  8    6         43         11         1
## 109    2   9  9    2         36         11         1
## 110    2  10 10    4         36          3         0
## 111    2  11 11    5         38         16         1
## 112    2  12 12    9         47         14         0
## 113    2  13 13    0         32          3         1
## 114    2  14 14    6         44         12         0
## 115    2  15 15    3         34         13         0
## 116    2  16 16    6         42          8         1
## 117    2  17 17    3         35         11         0
## 118    2  18 18    1         31          1         0
## 119    2  19 19    2         31          7         0
## 120    2  20 20    4         32          9         1
## 121    2  21 21    5         34         13         0
## 122    2  22 22    5         39         12         0
## 123    2  23 23    4         34          8         1
## 124    2  24 24    8         47         13         1
## 125    2  25 25    5         39          6         0
## 126    2  26 26    5         38         16         1
## 127    2  27 27    9         43         23         1
## 128    2  28 28    3         36          3         1
## 129    2  29 29    2         36          9         0
## 130    2  30 30    6         37         16         0
## 131    2  31 31   10         47         21         1
## 132    2  32 32    4         37          8         0
## 133    2  33 33   10         42         20         1
## 134    2  34 34    2         37          3         0
## 135    2  35 35    6         44         12         1
## 136    2  36 36    3         38          7         1
## 137    2  37 37    8         42          8         0
## 138    2  38 38    3         38          6         1
## 139    2  39 39    3         39          8         0
## 140    2  40 40    7         44         15         0
## 141    2  41 41    7         45         10         0
## 142    2  42 42    6         40         12         1
## 143    2  43 43    7         40         16         1
## 144    2  44 44    1         34          2         0
## 145    2  45 45    9         41         19         0
## 146    2  46 46    5         41         17         0
## 147    2  47 47    6         43         11         0
## 148    2  48 48    3         39          9         0
## 149    2  49 49    2         37          6         1
## 150    2  50 50    8         45         19         0
## 151    3   1  1    9         45         20         1
## 152    3   2  2    6         44         10         0
## 153    3   3  3    1         36          1         0
## 154    3   4  4    5         38         14         0
## 155    3   5  5    6         44         14         1
## 156    3   6  6    7         47         11         1
## 157    3   7  7    8         43         18         0
## 158    3   8  8    6         43         11         1
## 159    3   9  9    2         31         11         1
## 160    3  10 10    4         36          3         0
## 161    3  11 11    5         38         16         1
## 162    3  12 12    9         47         14         0
## 163    3  13 13    0         32          3         1
## 164    3  14 14    6         40         12         0
## 165    3  15 15    3         34         13         0
## 166    3  16 16    6         42          8         1
## 167    3  17 17    3         35         11         0
## 168    3  18 18    1         31          1         0
## 169    3  19 19    2         31          7         0
## 170    3  20 20    4         32          9         1
## 171    3  21 21    5         39         13         0
## 172    3  22 22    5         39         12         0
## 173    3  23 23    4         34          8         1
## 174    3  24 24    8         47         13         1
## 175    3  25 25    5         42          6         0
## 176    3  26 26    5         38         16         1
## 177    3  27 27    9         45         23         1
## 178    3  28 28    3         36          3         1
## 179    3  29 29    2         36          9         0
## 180    3  30 30    6         37         16         0
## 181    3  31 31   10         47         21         1
## 182    3  32 32    4         37          8         0
## 183    3  33 33   10         42         20         1
## 184    3  34 34    2         37          3         0
## 185    3  35 35    6         43         12         1
## 186    3  36 36    3         38          7         1
## 187    3  37 37    8         47          8         0
## 188    3  38 38    3         38          6         1
## 189    3  39 39    3         39          8         0
## 190    3  40 40    7         44         15         0
## 191    3  41 41    7         45         10         0
## 192    3  42 42    6         40         12         1
## 193    3  43 43    7         40         16         1
## 194    3  44 44    1         34          2         0
## 195    3  45 45    9         41         19         0
## 196    3  46 46    5         41         17         0
## 197    3  47 47    6         43         11         0
## 198    3  48 48    3         39          9         0
## 199    3  49 49    2         36          6         1
## 200    3  50 50    8         43         19         0
## 201    4   1  1    9         45         20         1
## 202    4   2  2    6         45         10         0
## 203    4   3  3    1         36          1         0
## 204    4   4  4    5         38         14         0
## 205    4   5  5    6         44         14         1
## 206    4   6  6    7         47         11         1
## 207    4   7  7    8         43         18         0
## 208    4   8  8    6         43         11         1
## 209    4   9  9    2         31         11         1
## 210    4  10 10    4         36          3         0
## 211    4  11 11    5         38         16         1
## 212    4  12 12    9         47         14         0
## 213    4  13 13    0         32          3         1
## 214    4  14 14    6         40         12         0
## 215    4  15 15    3         34         13         0
## 216    4  16 16    6         42          8         1
## 217    4  17 17    3         35         11         0
## 218    4  18 18    1         31          1         0
## 219    4  19 19    2         31          7         0
## 220    4  20 20    4         32          9         1
## 221    4  21 21    5         41         13         0
## 222    4  22 22    5         39         12         0
## 223    4  23 23    4         34          8         1
## 224    4  24 24    8         47         13         1
## 225    4  25 25    5         40          6         0
## 226    4  26 26    5         38         16         1
## 227    4  27 27    9         45         23         1
## 228    4  28 28    3         36          3         1
## 229    4  29 29    2         36          9         0
## 230    4  30 30    6         37         16         0
## 231    4  31 31   10         41         21         1
## 232    4  32 32    4         37          8         0
## 233    4  33 33   10         42         20         1
## 234    4  34 34    2         37          3         0
## 235    4  35 35    6         44         12         1
## 236    4  36 36    3         38          7         1
## 237    4  37 37    8         45          8         0
## 238    4  38 38    3         38          6         1
## 239    4  39 39    3         39          8         0
## 240    4  40 40    7         44         15         0
## 241    4  41 41    7         45         10         0
## 242    4  42 42    6         40         12         1
## 243    4  43 43    7         40         16         1
## 244    4  44 44    1         32          2         0
## 245    4  45 45    9         41         19         0
## 246    4  46 46    5         41         17         0
## 247    4  47 47    6         43         11         0
## 248    4  48 48    3         39          9         0
## 249    4  49 49    2         31          6         1
## 250    4  50 50    8         42         19         0
## 251    5   1  1    9         45         20         1
## 252    5   2  2    6         39         10         0
## 253    5   3  3    1         36          1         0
## 254    5   4  4    5         38         14         0
## 255    5   5  5    6         44         14         1
## 256    5   6  6    7         44         11         1
## 257    5   7  7    8         43         18         0
## 258    5   8  8    6         43         11         1
## 259    5   9  9    2         31         11         1
## 260    5  10 10    4         36          3         0
## 261    5  11 11    5         38         16         1
## 262    5  12 12    9         47         14         0
## 263    5  13 13    0         32          3         1
## 264    5  14 14    6         37         12         0
## 265    5  15 15    3         34         13         0
## 266    5  16 16    6         42          8         1
## 267    5  17 17    3         35         11         0
## 268    5  18 18    1         31          1         0
## 269    5  19 19    2         31          7         0
## 270    5  20 20    4         32          9         1
## 271    5  21 21    5         38         13         0
## 272    5  22 22    5         39         12         0
## 273    5  23 23    4         34          8         1
## 274    5  24 24    8         47         13         1
## 275    5  25 25    5         39          6         0
## 276    5  26 26    5         38         16         1
## 277    5  27 27    9         45         23         1
## 278    5  28 28    3         36          3         1
## 279    5  29 29    2         36          9         0
## 280    5  30 30    6         37         16         0
## 281    5  31 31   10         47         21         1
## 282    5  32 32    4         37          8         0
## 283    5  33 33   10         42         20         1
## 284    5  34 34    2         37          3         0
## 285    5  35 35    6         40         12         1
## 286    5  36 36    3         38          7         1
## 287    5  37 37    8         45          8         0
## 288    5  38 38    3         38          6         1
## 289    5  39 39    3         39          8         0
## 290    5  40 40    7         44         15         0
## 291    5  41 41    7         45         10         0
## 292    5  42 42    6         40         12         1
## 293    5  43 43    7         40         16         1
## 294    5  44 44    1         31          2         0
## 295    5  45 45    9         41         19         0
## 296    5  46 46    5         41         17         0
## 297    5  47 47    6         43         11         0
## 298    5  48 48    3         39          9         0
## 299    5  49 49    2         37          6         1
## 300    5  50 50    8         43         19         0</code></pre>
<p>In the imputed datasets two variables are added, an .id variable and an .imp variable to distinguish the cases in the dataset and the imputed datasets. The imputed datasets can be further used in mice to conduct pooled analyses or to store them for further use in other software packages as SPSS.</p>
<div id="customizing-the-imputation-model" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Customizing the Imputation model</h3>
<p>In the exemplar imputation model, the variables Tampa scale and Disability are imputed with the help of variables Pain and Radiation. The latter two variables are called auxiliary variables when they are not part of the main analysis model but they help to impute the Tampa scale and disability variables. Variables that are used to impute other variables can be switched off and on in the predictormatrix.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>PredictorMatrix</code></pre></div>
<pre><code>## NULL</code></pre>
<p>The predictor matrix is a matrix with the names of the variables in the dataset listed in the rows and the columns. The variables in the columns are used to impute the row variables. Accordingly, variables in the columns can be switched on or off to in- or exclude them from the imputation model to impute the missing data in the row variable. In our example, the first and fourth rows contain only zeroes, because the Pain and Radiation variables do not have missing values and therefore do not need to be imputed. The variable in the second row, i.e.Â Tampa scale, contains missing values and the 1Â´s in this row mean that the column variables Pain, Disability and Radiation are included in the imputation model. For the Disability variable, the variables Pain, Tampa scale and Radiation are used. As a default setting all variables are included in the imputation model to predict missing values in other variables. The diagonal of the predictormatrix is always zero. The predictormatrix can be adapted when for example a variable that contains a high percentage of missing data should be excluded from the imputation model to impute other variables. For example, if we want to exclude the variable Disability from the imputation model of the Tampa scale variable we can do the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred &lt;-imp<span class="op">$</span>PredictorMatrix
pred[<span class="st">&quot;Tampascale&quot;</span>, <span class="st">&quot;Disability&quot;</span>] &lt;-<span class="st"> </span><span class="dv">0</span>
pred

imp2 &lt;-<span class="st"> </span><span class="kw">mice</span>(data,<span class="dt">m=</span><span class="dv">5</span>, <span class="dt">maxit=</span><span class="dv">10</span>, <span class="dt">method=</span><span class="st">&quot;pmm&quot;</span>, <span class="dt">predictorMatrix =</span> pred, <span class="dt">seed=</span><span class="dv">1050</span>)</code></pre></div>
<p>In literature several guidelines for the imputation model are described @ref(COLLINS2001} <a href="#VANBUUREN2018"><strong>??</strong></a> <a href="#RUBIN1976"><strong>??</strong></a>. A summary of guidelines for building the imputation model is as follows:</p>
<ol style="list-style-type: decimal">
<li>Include all variables that are part of the analysis model, including the dependent (outcome) variable.</li>
<li>Include the variables at the same way in the imputation model as they appear in the analysis model (i.e.Â if interaction terms are in the analysis model they also have to be included in the imputation model).</li>
<li>Include additional (auxiliary) variables that are related to missingness or to variables with missing values.</li>
</ol>
</div>
</div>
<div id="output-of-the-mice-function" class="section level2">
<h2><span class="header-section-number">3.7</span> Output of the <code>mice</code> function</h2>
<p>The mice function returns a mids (multiple imputed data set) object. In this object, aimputation information is stored and can be extracted by typing <code>imp$</code>, followed by the type of information you want to obtain.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>m</code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>nmis</code></pre></div>
<pre><code>##         ID       Pain Tampascale Disability  Radiation 
##          0          0         13          0          0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>seed</code></pre></div>
<pre><code>## [1] NA</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>iteration</code></pre></div>
<pre><code>## [1] 10</code></pre>
<p>The above objects contain the the number of imputed datasets, missing values in each variable, the specified seed value and the number of iterations. The original data can be found in:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>data</code></pre></div>
<pre><code>##    ID Pain Tampascale Disability Radiation
## 1   1    9         45         20         1
## 2   2    6         NA         10         0
## 3   3    1         36          1         0
## 4   4    5         38         14         0
## 5   5    6         44         14         1
## 6   6    7         NA         11         1
## 7   7    8         43         18         0
## 8   8    6         43         11         1
## 9   9    2         NA         11         1
## 10 10    4         36          3         0
## 11 11    5         38         16         1
## 12 12    9         47         14         0
## 13 13    0         32          3         1
## 14 14    6         NA         12         0
## 15 15    3         34         13         0
## 16 16    6         42          8         1
## 17 17    3         35         11         0
## 18 18    1         31          1         0
## 19 19    2         31          7         0
## 20 20    4         32          9         1
## 21 21    5         NA         13         0
## 22 22    5         39         12         0
## 23 23    4         34          8         1
## 24 24    8         47         13         1
## 25 25    5         NA          6         0
## 26 26    5         38         16         1
## 27 27    9         NA         23         1
## 28 28    3         36          3         1
## 29 29    2         36          9         0
## 30 30    6         37         16         0
## 31 31   10         NA         21         1
## 32 32    4         37          8         0
## 33 33   10         42         20         1
## 34 34    2         37          3         0
## 35 35    6         NA         12         1
## 36 36    3         38          7         1
## 37 37    8         NA          8         0
## 38 38    3         38          6         1
## 39 39    3         39          8         0
## 40 40    7         44         15         0
## 41 41    7         45         10         0
## 42 42    6         40         12         1
## 43 43    7         40         16         1
## 44 44    1         NA          2         0
## 45 45    9         41         19         0
## 46 46    5         41         17         0
## 47 47    6         43         11         0
## 48 48    3         39          9         0
## 49 49    2         NA          6         1
## 50 50    8         NA         19         0</code></pre>
<p>The imputed values for each variable in the imptued values can be found under:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>imp</code></pre></div>
<pre><code>## $ID
## [1] 1 2 3 4 5
## &lt;0 rows&gt; (or 0-length row.names)
## 
## $Pain
## [1] 1 2 3 4 5
## &lt;0 rows&gt; (or 0-length row.names)
## 
## $Tampascale
##     1  2  3  4  5
## 2  44 37 44 45 39
## 6  40 40 47 47 44
## 9  31 36 31 31 31
## 14 37 44 40 40 37
## 21 37 34 39 41 38
## 25 42 39 42 40 39
## 27 45 43 45 45 45
## 31 47 47 47 41 47
## 35 43 44 43 44 40
## 37 47 42 47 45 45
## 44 36 34 34 32 31
## 49 39 37 36 31 37
## 50 47 45 43 42 43
## 
## $Disability
## [1] 1 2 3 4 5
## &lt;0 rows&gt; (or 0-length row.names)
## 
## $Radiation
## [1] 1 2 3 4 5
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<p>The imputation methods used:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>method</code></pre></div>
<pre><code>##         ID       Pain Tampascale Disability  Radiation 
##         &quot;&quot;         &quot;&quot;      &quot;pmm&quot;         &quot;&quot;         &quot;&quot;</code></pre>
<p>The predictor matrix:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>predictorMatrix</code></pre></div>
<pre><code>##            ID Pain Tampascale Disability Radiation
## ID          0    1          1          1         1
## Pain        1    0          1          1         1
## Tampascale  1    1          0          1         1
## Disability  1    1          1          0         1
## Radiation   1    1          1          1         0</code></pre>
<p>The sequence of the variables used in the impution procedure:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>visitSequence</code></pre></div>
<pre><code>## [1] &quot;ID&quot;         &quot;Pain&quot;       &quot;Tampascale&quot; &quot;Disability&quot; &quot;Radiation&quot;</code></pre>
<div id="checking-convergence-in-r" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Checking Convergence in R</h3>
<p>The convergence of the imputation procedure can be evaluates. The means of the imputed values for each iteration can be extracted from the mids object as chainMean. The number of Chains is equal to the number of imputed datasets. A Chain refers to the chain of regression models that is used to generate the imputed values. The length of each chain is equal to the number of iterations. The Chains contain the means of the imputed values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp<span class="op">$</span>chainMean</code></pre></div>
<pre><code>## , , Chain 1
## 
##                   1   2        3        4        5        6        7
## ID              NaN NaN      NaN      NaN      NaN      NaN      NaN
## Pain            NaN NaN      NaN      NaN      NaN      NaN      NaN
## Tampascale 41.23077  40 38.92308 39.53846 40.92308 40.61538 38.30769
## Disability      NaN NaN      NaN      NaN      NaN      NaN      NaN
## Radiation       NaN NaN      NaN      NaN      NaN      NaN      NaN
##                   8        9       10
## ID              NaN      NaN      NaN
## Pain            NaN      NaN      NaN
## Tampascale 39.61538 41.30769 41.15385
## Disability      NaN      NaN      NaN
## Radiation       NaN      NaN      NaN
## 
## , , Chain 2
## 
##                   1        2        3        4        5        6        7
## ID              NaN      NaN      NaN      NaN      NaN      NaN      NaN
## Pain            NaN      NaN      NaN      NaN      NaN      NaN      NaN
## Tampascale 40.30769 39.53846 40.53846 39.53846 39.61538 39.84615 39.53846
## Disability      NaN      NaN      NaN      NaN      NaN      NaN      NaN
## Radiation       NaN      NaN      NaN      NaN      NaN      NaN      NaN
##                   8        9       10
## ID              NaN      NaN      NaN
## Pain            NaN      NaN      NaN
## Tampascale 39.84615 40.84615 40.15385
## Disability      NaN      NaN      NaN
## Radiation       NaN      NaN      NaN
## 
## , , Chain 3
## 
##                   1        2        3        4        5        6        7
## ID              NaN      NaN      NaN      NaN      NaN      NaN      NaN
## Pain            NaN      NaN      NaN      NaN      NaN      NaN      NaN
## Tampascale 40.30769 41.30769 41.46154 40.92308 40.46154 41.23077 39.84615
## Disability      NaN      NaN      NaN      NaN      NaN      NaN      NaN
## Radiation       NaN      NaN      NaN      NaN      NaN      NaN      NaN
##                   8        9       10
## ID              NaN      NaN      NaN
## Pain            NaN      NaN      NaN
## Tampascale 40.30769 39.84615 41.38462
## Disability      NaN      NaN      NaN
## Radiation       NaN      NaN      NaN
## 
## , , Chain 4
## 
##                   1        2        3        4        5        6   7
## ID              NaN      NaN      NaN      NaN      NaN      NaN NaN
## Pain            NaN      NaN      NaN      NaN      NaN      NaN NaN
## Tampascale 40.53846 40.53846 40.69231 40.69231 39.92308 40.23077  39
## Disability      NaN      NaN      NaN      NaN      NaN      NaN NaN
## Radiation       NaN      NaN      NaN      NaN      NaN      NaN NaN
##                   8        9       10
## ID              NaN      NaN      NaN
## Pain            NaN      NaN      NaN
## Tampascale 41.76923 40.07692 40.30769
## Disability      NaN      NaN      NaN
## Radiation       NaN      NaN      NaN
## 
## , , Chain 5
## 
##                   1        2   3        4        5        6        7
## ID              NaN      NaN NaN      NaN      NaN      NaN      NaN
## Pain            NaN      NaN NaN      NaN      NaN      NaN      NaN
## Tampascale 39.76923 39.69231  40 39.76923 40.07692 39.84615 41.15385
## Disability      NaN      NaN NaN      NaN      NaN      NaN      NaN
## Radiation       NaN      NaN NaN      NaN      NaN      NaN      NaN
##                   8   9       10
## ID              NaN NaN      NaN
## Pain            NaN NaN      NaN
## Tampascale 40.07692  41 39.69231
## Disability      NaN NaN      NaN
## Radiation       NaN NaN      NaN</code></pre>
<p>The convergence can be visualised by plotting the chain information in a convergence plot. For our example, the convergence plots are shown below. In this plot you see that the variance between the imputation chains is almost equal to the variance within the chains, which indicates healthy convergence.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(imp)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-72-1.png" width="672" /></p>
</div>
<div id="imputation-diagnostics-in-r" class="section level3">
<h3><span class="header-section-number">3.7.2</span> Imputation diagnostics in R</h3>
<p>It can also be of interest to compare the values that are imputed with those that are observed. For that, the <code>stripplot</code> function can be used in <code>mice</code>. This function visualises the observed and imputed values in one plot. By comparing the observed and the imputed data points we get an idea if the imputed values are in range of the observed data. If there are no large differences between the imputed and observed values under MAR than we can conclude the imputed values are plausible.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">stripplot</span>(imp)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
</div>
</div>
<div id="multiple-imputation-in-spss" class="section level2">
<h2><span class="header-section-number">3.8</span> Multiple imputation in SPSS</h2>
<p>The multiple imputation procedure in SPSS is based on the MICE algorithm that was developed in R. It is therefore no surprise that the settings of the mice function in R, are almost all covered by the options in SPSS. Before you start the MI procedure it is important to set the measurement level of the variables with missing data in the Variable View window of your data. They are important for the regression model that is used to estimate the missing values in that variable. For example, if you define a variable as scale, then linear regression models are used, for categorical variables, logistic regression models are used.</p>
<div id="multiple-imputation-in-spss-1" class="section level3">
<h3><span class="header-section-number">3.8.1</span> Multiple imputation in SPSS</h3>
<p>Before we start the multiple imputation procedure, we set the starting point of the random number generator in SPSS at a fixed value of 950 (in R we use the seed for this). In this way we are able to reproduce results exactly. This fixing of starting values for the random number generator is in general not advisable, we use it here for educational purposes.</p>
<p>We set the random number generator in SPSS via</p>
<blockquote>
<p>Transform -&gt; Random Number Generators -&gt; Set Starting point -&gt; Fixed Value</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:fig4-5"></span>
<img src="images/fig4.5.png" alt="Set the Random Number Generator " width="90%" />
<p class="caption">
Figure 3.23: Set the Random Number Generator
</p>
</div>
<p>The multiple imputation procedure in SPSS can be started via</p>
<blockquote>
<p>Analyze -&gt; Multiple Imputation -&gt; Impute Missing Data Values.</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:fig4-6"></span>
<img src="images/fig4.6.png" alt="The variables Tab" width="90%" />
<p class="caption">
Figure 3.24: The variables Tab
</p>
</div>
<p>In the Variables tab the variables that are part of the imputation model have to be transported to the window â€œVariables in Modelâ€. The variables are imputed sequentially in the order in which they are listed in the variables list. These variables are in our example the Pain, Tampascale, Disability and Radiation variables. Further, the number of imputed datasets can be defined as well as the dataset to which the imputed data values are saved. We choose for 5 imputations and call the dataset in which the imputed values will be stored â€œLBP_Impâ€. In the Methods Tab the imputation method is defined.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-7"></span>
<img src="images/fig4.7.png" alt="The Methods Tab" width="90%" />
<p class="caption">
Figure 3.25: The Methods Tab
</p>
</div>
<p>In the Method tab we choose for a â€œCustomâ€ under Imputation Method and for Fully conditional specification. The Fully Conditional Specification (FCS) procedure is the Bayesian sequential regression imputation method as explained in <em>section 4.3 and 4.4</em>. Under Model type for scale (continuous) variables we choose for Predictive Mean Matching. This procedure was explained in <em>section 3.7</em>. In the <code>mice</code> package PMM is the default procedure for continuous variables with missing data. In SPSS the default is the linear regression procedure. In the Constraints Tab the options per variable are defined.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-8"></span>
<img src="images/fig4.8.png" alt="The Constraints Tab" width="90%" />
<p class="caption">
Figure 3.26: The Constraints Tab
</p>
</div>
<p>In the Constraints tab the role of a variable during the imputation process is defined and it is possible to restrict the range of imputed values of a scale variable. In addition, you can restrict the analysis to variables with less than a maximum percentage of missing values. When the PMM method is selected in the Method Tab, the Constraints tab can be skipped. Finally, in the Output Tab the generated output can be defined.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-9"></span>
<img src="images/fig4.9.png" alt="The Output Tab" width="90%" />
<p class="caption">
Figure 3.27: The Output Tab
</p>
</div>
<p>Display the Imputation model and the Descriptive statistics for variables with imputed values options can be selected for information about the imputation. When the FCS imputation method is used, you can request a dataset that contains iteration history data for FCS imputation. In our example this iteration history information is stored in the dataset â€œIter_Backpainâ€. The dataset contains means and standard deviations by iteration for each scale variable for which values are imputed. You can plot the data to help assess model convergence.</p>
</div>
<div id="the-output-for-multiple-imputation-in-spss" class="section level3">
<h3><span class="header-section-number">3.8.2</span> The output for Multiple imputation in SPSS</h3>
<p>After the multiple imputation procedure is done, a new data window opens that contains the imputed datasets. These multiple imputed datasets are stacked on top of each other. In this file the imputed values are marked yellow. There is also an extra variable added to the file which is called <code>Imputation_</code> (Figure <a href="single-missing-data-imputation.html#fig:fig4-10">3.28</a>). The imputed values can be marked and unmarked via</p>
<blockquote>
<p>View -&gt; Mark Imputed data</p>
</blockquote>
<p>If you switch this possibility on, SPSS automatically recognizes the dataset as a multiple imputed dataset. If you switch this possibility off, SPSS treats the dataset as one dataset. This marking and unmarking can also be done in the Data view window via the button with yellow and white squares on the right site above (Figure <a href="single-missing-data-imputation.html#fig:fig4-11">3.29</a>). If you click the button, a selection box appears with â€œOriginal dataâ€ selected,where you can easily move to the different imputed datasets. The variable <code>Imputation_</code> is a variable with a nominal measure. You can compare the use of this variable with the Split File option in SPSS where all analyses are done separately for the categories of the variable use to split the analyses. The difference is that with the <code>Imputation_</code> variable you also obtain pooled estimates for the statistical analyses.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-10"></span>
<img src="images/fig4.10.png" alt="Example of Multiple Imputed dataset" width="90%" />
<p class="caption">
Figure 3.28: Example of Multiple Imputed dataset
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig4-11"></span>
<img src="images/fig4.11.png" alt="Button and selection box to mark imputed values" width="90%" />
<p class="caption">
Figure 3.29: Button and selection box to mark imputed values
</p>
</div>
<p>The iteration history is stored in the Iter_Backpain dataset as we defined in the Output window. In this dataset the means and standard deviations of the imputed values at each iteration are stored. These values can be used to construct Convergence plots. More about making convergence plots will be discussed in the next paragraph.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-12"></span>
<img src="images/fig4.12.png" alt="The iteration history data" width="90%" />
<p class="caption">
Figure 3.30: The iteration history data
</p>
</div>
<p>Based on our settings, SPSS produces the following results in the output window. In the Imputation Specifications table, information is provided on the imputation method used, the number of imputations, the model used for the scale variables, if interactions were included in the imputation models, the setting for the maximum percentage of missing values and the setting for the maximum number of parameters in the imputation model (Figure <a href="single-missing-data-imputation.html#fig:tab4-4">3.31</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:tab4-4"></span>
<img src="images/tab4.4.png" alt="Imputation Specifications table" width="90%" />
<p class="caption">
Figure 3.31: Imputation Specifications table
</p>
</div>
<p>A second table, called Imputation Results, is presented with information about the imputation method, the number of fully conditional specification methods, the variables that are imputed and not imputed and the imputation sequence(Figure <a href="single-missing-data-imputation.html#fig:tab4-5">3.32</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:tab4-5"></span>
<img src="images/tab4.5.png" alt="Imputation Results" width="90%" />
<p class="caption">
Figure 3.32: Imputation Results
</p>
</div>
<p>The Imputation Models table presents information about the imputation models used for the variables with missing data (Figure <a href="single-missing-data-imputation.html#fig:tab4-6">3.33</a>). Information is provided about the method of imputation, under the type column, the effect estimates used to impute the missing values, the number of missing and imputed values. For example for the Tampascale variable 13 values were missing and m=5 times 13 is 65 values were imputed.</p>
<div class="figure" style="text-align: center"><span id="fig:tab4-6"></span>
<img src="images/tab4.6.png" alt="Imputation Models" width="90%" />
<p class="caption">
Figure 3.33: Imputation Models
</p>
</div>
<p>The Descriptive statistics display the descriptive information of the original, imputed and completed data of the Tampascale and the Disability variable. In this way you can compare the completed data after MI with the original data.</p>
<div class="figure" style="text-align: center"><span id="fig:tab4-7"></span>
<img src="images/tab4.7.png" alt="Descriptive statistics" width="90%" />
<p class="caption">
Figure 3.34: Descriptive statistics
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:tab4-7"></span>
<img src="images/tab4.8.png" alt="Descriptive statistics" width="90%" />
<p class="caption">
Figure 3.34: Descriptive statistics
</p>
</div>
</div>
<div id="checking-convergence-after-multiple-imputation-in-spss" class="section level3">
<h3><span class="header-section-number">3.8.3</span> Checking Convergence after Multiple imputation in SPSS</h3>
<p>The dataset Iter_Backpain in the previous paragraph contains the means and standard deviations of the imputed values at each iteration and imputation round. This information is similar as the information in <code>imp$chainMean</code> in R. This dataset can be used to generate convergence plots, to check if the imputed values have the expected variation between the iterations.The iteration can be checked for the means and standard deviations seperately. In order to obtain seperate plots for htese summary statistics, the split file option in SPSS can be activated.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-17"></span>
<img src="images/fig4.17.png" alt="Split file" width="90%" />
<p class="caption">
Figure 3.35: Split file
</p>
</div>
<p>After activation of the split file option, the Graph menu in SPSS can be used to make the plots.</p>
<blockquote>
<p>Graph -&gt; Char Builder.</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:fig4-13"></span>
<img src="images/fig4.13.png" alt="Graph menu" width="90%" />
<p class="caption">
Figure 3.36: Graph menu
</p>
</div>
<p>Two windows will open that can be used to build a chart:</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-14"></span>
<img src="images/fig4.14.png" alt="Chart Builder" width="90%" />
<p class="caption">
Figure 3.37: Chart Builder
</p>
</div>
<p>On the x-axis the put the <code>iteration number</code> variable and on the y-axis the variable for which we want to display the iteration history. The <code>Imputation Number</code> variable is dragged to the <code>set color</code> top-right.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-15"></span>
<img src="images/fig4.15.png" alt="Chart Builder" width="90%" />
<p class="caption">
Figure 3.38: Chart Builder
</p>
</div>
<p>As a result two plots appear with the iteation history for each imputation run.</p>
<div class="figure" style="text-align: center"><span id="fig:fig4-18"></span>
<img src="images/fig4.18.png" alt="Convergence plots" width="90%" />
<p class="caption">
Figure 3.39: Convergence plots
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig4-18"></span>
<img src="images/fig4.19.png" alt="Convergence plots" width="90%" />
<p class="caption">
Figure 3.39: Convergence plots
</p>
</div>
</div>
</div>
<div id="number-of-imputed-datasets-and-iterations" class="section level2">
<h2><span class="header-section-number">3.9</span> Number of Imputed datasets and iterations</h2>
<p>Researchers assume that the number of imputations needed to generate valid imputations has to be set at 3-5 imputations. This idea was based on the work of Rubin <a href="#RUBIN1987"><strong>??</strong></a>. He showed that the precision of a pooled parameter becomes lower when a finite number of multiply imputed datasets is used compared to an infinite number (finite means a limited number of imputed datasets, like 5 imputed datasets and infinite means unlimited and can be recognized by the mathematical symbol âˆž). The precision of a parameter is often represented by the sampling variance (or standard error (SE) estimate; the sampling variance is equal to SE2) of for example a regression coefficient. In case of multiple imputed datasets precision is determined by the pooled sampling variance or pooled SE. A measure to value the amount of precision (i.e.Â between the pooled sampling variance estimated in a finite compared to an infinite number of imputed datasets) is the relative efficiency (<span class="math inline">\(RE\)</span>). The <span class="math inline">\(RE\)</span> is low when the number of imputations is high (and the precision becomes larger) and is defined as:</p>
<p><span class="math display">\[RE=  \frac{1}{1+ \frac{FMI}{m}}\]</span></p>
<p>FMI is the fraction of missing information and m is the number of imputed datasets. Where FMI is roughly equal to the percentage of missing data in the simplest case of one variable with missing data. When there are more variables in the imputation model, and these variables are correlated with the variables with missing data the FMI becomes lower.</p>
<p>The relationship between the <span class="math inline">\(RE\)</span> and the pooled sampling variance ($T_) can be written as <a href="#VANBUUREN2012"><strong>??</strong></a>: <span class="math display">\[T_{Pooled,finite}=REÃ—T_{Pooled,infinite}\]</span> which is equal to: <span class="math display">\[SE_{Pooled,finite}^2=REÃ—SE_{Pooled,infinite}^2 \]</span></p>
<p>These can be interpreted as follows: if the <span class="math inline">\(RE\)</span> is 0.93 for FMI=0.4 and m=5, <span class="math inline">\(T_{Pooled,finite}\)</span> is:</p>
<p><span class="math display">\[T_{Pooled,finite}=0.93Ã—T_{Pooled,infinite}\]</span></p>
<p>Accordingly, when 5 imputed datasets are used, the standard error <span class="math inline">\(SE\)</span> is âˆš0.93=0.96 times as large as the <span class="math inline">\(SE\)</span> when an infinite number of imputed datasets are used. Because the <span class="math inline">\(RE\)</span> is divided by 1, when 5 imputed datasets are used, the <span class="math inline">\(SE\)</span> is 1/âˆš0.93=1.04 times larger (or 4%) than the <span class="math inline">\(SE\)</span> when an infinite number of imputed datasets are used. Graham <a href="#GRAHAM2007"><strong>??</strong></a> also studied the loss in power when infinite numbers of imputed datasets are used. They recommended that at least 20 imputed datasets are needed to restrict the loss of power when testing a relationship between variables. Bodner <a href="#BODNER2008"><strong>??</strong></a> proposed the following guidelines after a simulation study using different values for the FMI to determine the number of imputed datasets. For FMIÂ´s of 0.05, 0.1, 0.2, 0.3, 0.5 the following number of imputed dataets are needed: â‰¥3, 6, 12, 24, 59, respectively. Following the study of Bodner <a href="#BODNER2008"><strong>??</strong></a>, White et al. <a href="#WHITE2010"><strong>??</strong></a>, proposed a rule of thumb, based on the idea that the FMI is frequently lower than the percentage of missing cases. Their rule of thumb states that the number of imputed datasets should be at least equal to the percentage of missing cases. This means that when 10% of the subjects have missing values, at least 10 imputed datasets should be generated.</p>
<p>Iterations Van Buuren <a href="#VANBUUREN2012"><strong>??</strong></a> states that the number of iterations may depend on the correlation between variables and the percentage of missing data in variables. He proposed that a number of 5-20 iterations is enough to reach convergence. This number may be adjusted when the percentage of missing data is high. Nowadays computers are fast so that a higher number of iterations can easily be used.</p>

</div>
</div>



<h2><span class="header-section-number">3.10</span> Pooling results after MI in SPSS</h2>
<div id="imputed-values-are-yellow" class="section level3">
<h3><span class="header-section-number">3.10.1</span> Imputed values are yellow</h3>
<p>After multiple imputation, the multiple imputed datasets are stored in a new SPSS file. In order to obtain pooled analysis results, the imputed values must be marked yellow. Than SPSS recognizes the dataset is an â€œimputedâ€ dataset and is able to generate pooled analyses results. Figure <a href="single-missing-data-imputation.html#fig:fig5-1">3.40</a>) shows an example of a multiple imputed dataset with imputed values marked yellow. If SPSS does not recognize the dataset as a multiple imputed dataset, the data will be treated as one large dataset.</p>
<div class="figure" style="text-align: center"><span id="fig:fig5-1"></span>
<img src="images/fig5.1.png" alt="Example of SPSS dataset after MI has been applied." width="90%" />
<p class="caption">
Figure 3.40: Example of SPSS dataset after MI has been applied.
</p>
</div>
<p>You can mark the imputed values by using the option â€œMark Imputed Dataâ€ under the View menu in the Data View window ((Figure <a href="single-missing-data-imputation.html#fig:fig5-1">3.40</a>)).</p>
</div>
<div id="the-imputation_-variable" class="section level3">
<h3><span class="header-section-number">3.10.2</span> The Imputation_ variable</h3>
<p>The Imputation_ variable is a nominal variable that separates the original from the imputed datasets. It is used as a variable that splits the file into separate groups for analysis based on the different categories. This is also indicated in the corner on the right side below in the Data View and Variable View windows by the note â€œSplit by imputation_â€.</p>
<div class="figure" style="text-align: center"><span id="fig:fig5-2"></span>
<img src="images/fig5.2.png" alt="Procedure to mark imputed values in SPSS." width="90%" />
<p class="caption">
Figure 3.41: Procedure to mark imputed values in SPSS.
</p>
</div>
<p>When missing values are imputed with any another software program, you can include an Imputation_ variable in SPSS. It is than recognized as an imputed dataset in SPSS.</p>
</div>
<div id="special-pooling-icon" class="section level3">
<h3><span class="header-section-number">3.10.3</span> Special pooling icon</h3>
<p>When imputation markings are turned on, a special icon is displayed next to the statistical procedures in the analyze menu. This icon shows you if a pooled result is generated after multiple imputation is used ((Figure <a href="single-missing-data-imputation.html#fig:fig5-3">3.42</a>)).</p>
<div class="figure" style="text-align: center"><span id="fig:fig5-3"></span>
<img src="images/fig5.3.png" alt="Multiple Imputation icon." width="5%" />
<p class="caption">
Figure 3.42: Multiple Imputation icon.
</p>
</div>
<p>This icon is shown in the analyze menu in SPSS (Figure <a href="single-missing-data-imputation.html#fig:fig5-4b">3.43</a>)).</p>
<div class="figure" style="text-align: center"><span id="fig:fig5-4b"></span>
<img src="images/fig5.4b.png" alt="The dataset is recognized as an imputed dataset (special icon visible)." width="90%" />
<p class="caption">
Figure 3.43: The dataset is recognized as an imputed dataset (special icon visible).
</p>
</div>
<p>SPSS provides two levels of pooling, which are called the NaÃ¯ve and Univariate combination. The NaÃ¯ve combination only shows the pooled parameter (if available). The Univariate combination shows the pooled parameter, its standard error, test statistic, effective degrees of freedom, p-value, confidence interval, and pooling diagnostics (fraction of missing information, relative efficiency, relative increase in variance), when available. Although the special icon in SPSS to indicate that the dataset is recognized as a multiple imputed dataset appears for many analysis procedures, it is not always clear what procedures really provide the Univariate combination output. It is therefore recommended to explore what kind of pooled information is provided by SPSS before MI is applied.</p>
</div>
</div>
<div id="pooling-results-after-mi-in-r" class="section level2">
<h2><span class="header-section-number">3.11</span> Pooling results after MI in R</h2>
<p>Many pooling procedures are available as part of the mice package. However, for some specific statistical procedures, other packages are required to obtain pooled estimates. For example, pooling ANOVA results is not available in the mice package itself. For this, the miceadds package has to be used.</p>
<p>For the examples in this Chapter We will use three imputed datasets, to keep the output Tables readable, although the examples easily generalize to a larger number of imputed datasets.</p>
</div>
<div id="pooling-means-and-standard-deviations-in-spss" class="section level2">
<h2><span class="header-section-number">3.12</span> Pooling Means and Standard deviations in SPSS</h2>
<p>To get pooled means you just use</p>
<blockquote>
<p>Analyze &gt; Descriptive Statistics.</p>
</blockquote>
<p>Figure <a href="single-missing-data-imputation.html#fig:tab5-3">3.44</a> shows that in the â€œPooledâ€ row the mean values of the Tampascale variable are pooled. The standard deviations are not automatically pooled in SPSS. The mean value of the standard deviations can be calculated by computing the average over the standard deviations.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-3"></span>
<img src="images/table5.3.png" alt="Pooling results of descriptive statistics." width="90%" />
<p class="caption">
Figure 3.44: Pooling results of descriptive statistics.
</p>
</div>
</div>
<div id="pooling-means-and-standard-deviations-in-r" class="section level2">
<h2><span class="header-section-number">3.13</span> Pooling Means and Standard Deviations in R</h2>
<p>To pool the means and standard deviations you use the with function in mice.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the SPSS dataset</span>
<span class="kw">library</span>(foreign)
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 Missing MI datasets.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mice)
<span class="co"># Apply multiple imputation</span>
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2375</span>, <span class="dt">printFlag =</span> F)
 
<span class="co"># Stack imputed datasets in long format, exclude the original data</span>
impdat &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dt">action=</span><span class="st">&quot;long&quot;</span>,<span class="dt">include =</span> <span class="ot">FALSE</span>)

<span class="co"># compute mean and standard deviation in each imputed dataset</span>
desc &lt;-<span class="st"> </span><span class="kw">with</span>(impdat, <span class="kw">by</span>(impdat, .imp, <span class="cf">function</span>(x) <span class="kw">c</span>(<span class="kw">mean</span>(x<span class="op">$</span>Tampascale),<span class="kw">sd</span>(x<span class="op">$</span>Tampascale))))
desc</code></pre></div>
<pre><code>## .imp: 1
## [1] 38.935000  5.330867
## -------------------------------------------------------- 
## .imp: 2
## [1] 38.988333  5.400321
## -------------------------------------------------------- 
## .imp: 3
## [1] 38.998333  5.391361</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Reduce</span>(<span class="st">&quot;+&quot;</span>,desc)<span class="op">/</span><span class="kw">length</span>(desc)</code></pre></div>
<pre><code>## [1] 38.973889  5.374183</code></pre>
</div>
<div id="pooling-correlation-coefficients" class="section level2">
<h2><span class="header-section-number">3.14</span> Pooling Correlation coefficients</h2>
<p>When a normal distribution of the parameter estimates cannot be assumed, like for the correlation coefficients, a Fishers Z transformation has to be performed before pooling (see the appendix for the formulaâ€™s). This is automatically done in SPSS and R.</p>
<div id="pooling-correlation-coefficients-in-spss" class="section level3">
<h3><span class="header-section-number">3.14.1</span> Pooling Correlation coefficients in SPSS</h3>
<p>A pooled Pearsons correlation coefficient between for example, the Tampascale and Age variables can be extracted using</p>
<blockquote>
<p>Analyse -&gt; Correlate -&gt; Bivariate.</p>
</blockquote>
<p>Than transfer the variable Tampa scale and Age to the variables window and click on OK. The pooled results are shown in (Figure <a href="single-missing-data-imputation.html#fig:tab5-4">3.45</a>), in the row called Pooled. The pooled correlation is 0.255, and the significance level is 0.002. These correlations are calculated using Fishers Z transformation before pooling and after pooling they are back-transformed.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-4"></span>
<img src="images/table5.4.png" alt="Pearson correlation between the Tampascale variable and Age." width="90%" />
<p class="caption">
Figure 3.45: Pearson correlation between the Tampascale variable and Age.
</p>
</div>
</div>
<div id="pooling-correlation-coefficients-in-r" class="section level3">
<h3><span class="header-section-number">3.14.2</span> Pooling Correlation Coefficients in R</h3>
<p>You can use the micombine.cor function in the miceadds package to obtain pooled correlation coefficients.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the dataset </span>
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Impute missing data using the mice function, with printFlag is F(alse), </span>
<span class="co"># which means that the imp and iter information is hided (called silent </span>
<span class="co"># computation)</span>
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2375</span>, <span class="dt">printFlag=</span>F)

<span class="co"># Run the micombine.cor function for the variables in column 2 </span>
<span class="co"># and 5, i.e. variables Tampascale and Age</span>
res.mi.cor &lt;-<span class="st"> </span><span class="kw">micombine.cor</span>(<span class="dt">mi.res=</span>imp, <span class="dt">variables =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">5</span>) )
res.mi.cor</code></pre></div>
<pre><code>##    variable1  variable2        r        rse  fisher_r fisher_rse
## 1 Tampascale        Age 0.252762 0.07748072 0.2583611 0.08278965
## 2        Age Tampascale 0.252762 0.07748072 0.2583611 0.08278965
##           fmi        t           p    lower95   upper95
## 1 0.007555655 3.120693 0.001804258 0.09580167 0.3974575
## 2 0.007555655 3.120693 0.001804258 0.09580167 0.3974575</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Ouput of the micombine.cor function, with in the columns:</span>
<span class="co">#   r: Pooled Pearsons correlation coefficient.</span>
<span class="co">#     rse: Standard error of pooled correlation.</span>
<span class="co">#     fisher_r: Transformed pooled r</span>
<span class="co">#     fisher_rse: Standard error of transformed pooled r</span>
<span class="co">#     fmi: Fraction of missing information.</span>
<span class="co">#     t: T-value.</span>
<span class="co">#     p: P-value.</span>
<span class="co">#     lower95 and upper95: 95% lower and upper confidence intervals.</span></code></pre></div>
</div>
</div>
<div id="the-pooled-independent-t-test" class="section level2">
<h2><span class="header-section-number">3.15</span> The Pooled Independent T-test</h2>
<p>To pool the independent t-test, RubinÂ´s Rules can be used. These steps are discussed in detail, including the formulaâ€™s to get the results, in Chapter 9.</p>
<div id="pooling-independent-t-tests-in-spss" class="section level3">
<h3><span class="header-section-number">3.15.1</span> Pooling Independent T-tests in SPSS</h3>
<p>To get a pooled t-test result to estimate the difference in mean Tampascale values between patients with and without Radiation in the leg you go to:</p>
<blockquote>
<p>Analyze -&gt; Compare Means -&gt; Independent-Samples T Test</p>
</blockquote>
<p>Transport the Tampa Scale variable to the Test Variable(s) window and the Radiation variable to the Grouping Variable window. Than Click on Define Groups and Define Group 1 as â€œ1â€ and Group 2 as â€œ0â€. Than Click on Continue and OK. The following output table will show up, Figure <a href="single-missing-data-imputation.html#fig:tab5-1a">3.46</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-1a"></span>
<img src="images/table5.1.png" alt="T-test for difference in mean Tampascale values between patients with and without Radiation in the leg applied in multiple imputed datasets." width="90%" />
<p class="caption">
Figure 3.46: T-test for difference in mean Tampascale values between patients with and without Radiation in the leg applied in multiple imputed datasets.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:tab5-1b"></span>
<img src="images/table5.1b.png" alt="b.T-test for difference in mean Tampascale values between patients with and without Radiation in the leg applied in multiple imputed datasets." width="90%" />
<p class="caption">
Figure 3.47: b.T-test for difference in mean Tampascale values between patients with and without Radiation in the leg applied in multiple imputed datasets.
</p>
</div>
<p>The result in the original dataset (including missing values) is presented in the row that is indicated by Imputation_ number 0. Results in each imputed dataset are shown in the rows starting with number 1 to 3. In the last row which is indicated as â€œPooledâ€, the summary estimates of the mean differences, standard errors, p-values and 95% Confidence Interval are presented.</p>
</div>
<div id="pooling-independent-t-tests-in-r-with-mice" class="section level3">
<h3><span class="header-section-number">3.15.2</span> Pooling Independent T-tests in R with mice</h3>
<p>The mice package itself does not have a pooled t-test option. Instead a linear regression analysis has to be conducted. A linear regression analysis with a continuous outcome variable and an independent dichotomous variable is the same procedure as an independent t-test. Use for this the lm procedure in mice with as independent variable Radiation and dependent variable Tampascale.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Reading in the dataset</span>
<span class="kw">library</span>(foreign)
<span class="kw">library</span>(mice)

dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Impute the missing values using the mice function </span>
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2375</span>, <span class="dt">printFlag=</span>F)
 
<span class="co"># Conduct an independent t-test via lm in each imputed dataset</span>
fit.t.test &lt;-<span class="st"> </span><span class="kw">with</span>(<span class="dt">data=</span>imp, <span class="dt">exp=</span><span class="kw">lm</span>(Tampascale <span class="op">~</span><span class="st"> </span>Radiation))
t.test.estimates &lt;-<span class="st"> </span><span class="kw">pool</span>(fit.t.test)
<span class="kw">summary</span>(t.test.estimates)</code></pre></div>
<pre><code>##              estimate std.error statistic       df    p.value
## (Intercept) 38.153846 0.5628260  67.78977 141.2188 0.00000000
## Radiation    1.993047 0.9205375   2.16509 106.3217 0.03206084</code></pre>
<p>We see in the output, under est and se the same values as in SPSS (Figure <a href="single-missing-data-imputation.html#fig:tab5-4">3.45</a>), the pooled value of 1.97 and 0.92 for the mean difference and standard error respectively.</p>
<p>Under the column df in R you see that the dfs for the mean differences in the Tampascale variable are much smaller than those in (Figure <a href="single-missing-data-imputation.html#fig:tab5-4">3.45</a>) above. This is due to the different formulas used to calculate the df. SPSS uses an older version and mice an adjusted one (see Chapter 9 for more information about different ways to calculate the df between SPSS and R)</p>
</div>
<div id="pooling-independent-t-tests-in-r-with-mi.t.test" class="section level3">
<h3><span class="header-section-number">3.15.3</span> Pooling Independent T-tests in R with mi.t.test</h3>
<p>you can also use the mi.t.test function in the MKmisc package. Note that the mi.t.test function uses the parameter setting var.equal is True when equal variances are assumed and var.equal is False when equal variances are not assumed (the default setting is var.equal is False).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the dataset</span>
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use the mice function to impute the missing data</span>
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2375</span>, <span class="dt">printFlag=</span>F)
 
<span class="co"># Extract the imputed datasets and define the Radiation variable  </span>
<span class="co"># as a factor variable</span>
dataset1 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">1</span>)
dataset1<span class="op">$</span>Radiation &lt;-<span class="st"> </span><span class="kw">factor</span>(dataset1<span class="op">$</span>Radiation)
dataset2 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">2</span>)
dataset2<span class="op">$</span>Radiation &lt;-<span class="st"> </span><span class="kw">factor</span>(dataset2<span class="op">$</span>Radiation)
dataset3 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">3</span>)
dataset3<span class="op">$</span>Radiation &lt;-<span class="st"> </span><span class="kw">factor</span>(dataset3<span class="op">$</span>Radiation)
 
<span class="co"># Assign the imputed datasets to the list object dataset.imp</span>
dataset.imp &lt;-<span class="st"> </span><span class="kw">list</span>(dataset1, dataset2, dataset3)
 
<span class="co"># Start the MKmisc library and run the mi.t.test function to get pooled </span>
<span class="co"># results  of the t-test</span>
<span class="kw">library</span>(MKmisc)</code></pre></div>
<pre><code>## Warning: package &#39;MKmisc&#39; was built under R version 3.5.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Result of the pooled t-test</span>
<span class="kw">mi.t.test</span>(dataset.imp, <span class="dt">x =</span> <span class="st">&quot;Tampascale&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Radiation&quot;</span>, <span class="dt">var.equal =</span> T)</code></pre></div>
<pre><code>## 
##  Multiple Imputation Two Sample t-test
## 
## data:  Variable Tampascale: group 0 vs group 1
## t = -2.1651, df = 106.32, p-value = 0.03262
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -3.8180378 -0.1680552
## sample estimates:
##  mean (0)    SD (0)  mean (1)    SD (1) 
## 38.153846  5.597451 40.146893  5.198414</code></pre>
<p>With the mi.t.test function also a one sample and a paired t-test can be conducted.</p>
</div>
</div>
<div id="pooling-chi-square-tests" class="section level2">
<h2><span class="header-section-number">3.16</span> Pooling Chi-square tests</h2>
<div id="pooling-chi-square-tests-in-spss" class="section level3">
<h3><span class="header-section-number">3.16.1</span> Pooling Chi-square tests in SPSS</h3>
<p>The pooling of Chi-square values as a result of the Chi-square test is not available in SPSS. This lack of reporting of the Chi-Square test is shown in (Figure <a href="single-missing-data-imputation.html#fig:tab5-6">3.48</a>) where the association between the Tampa scale variable as a categorical variable (with the categories 0 = low fear of movement, 1 = middle fear of movement and 2 is a high fear of movement) and Radiation in the leg is studied. The Chi-square test is presented in the original dataset and in each imputed dataset, but a pooled Chi-square value and pooled p-value is missing. This is remarkable because when you choose for Descriptive Statistics -&gt; Crosstabs to conduct the Chi-square test the special Multiple Imputation icon is shown. This is an indication that you get pooled results, however in this case it is not.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-6"></span>
<img src="images/table5.6.png" alt="Chi-square test in 5 imputed dataset to test the relationship between the Tampascale variable and Radiation, where a pooled estimate is missing." width="90%" />
<p class="caption">
Figure 3.48: Chi-square test in 5 imputed dataset to test the relationship between the Tampascale variable and Radiation, where a pooled estimate is missing.
</p>
</div>
</div>
<div id="pooling-chi-square-tests-in-r" class="section level3">
<h3><span class="header-section-number">3.16.2</span> Pooling Chi-square tests in R</h3>
<p>Procedures to pool Chi-square values are available in the miceadds package. The pooling functions are based on formulas that can be found in Marshall (2009) and Enders (2012) and are referred to as the D2 statistic. To pool the Chi-square values of the SPSS example you use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(miceadds)
<span class="kw">micombine.chisquare</span>(<span class="kw">c</span>(<span class="fl">1.829</span>, <span class="fl">1.311</span>, <span class="fl">2.861</span>, <span class="fl">1.771</span>, <span class="fl">3.690</span>), <span class="dv">2</span>, <span class="dt">display =</span> <span class="ot">TRUE</span>, <span class="dt">version=</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## Combination of Chi Square Statistics for Multiply Imputed Data
## Using 5 Imputed Data Sets
## F(2, 240.99)=0.869     p=0.42056</code></pre>
<p>The function micombine.chisquare also has a parameter setting that is called â€œversionâ€. The default version=1 refers to the correct formula as in Enders (2010), while version=0 uses an incorrect formula as printed in Allison (2001).</p>
</div>
</div>
<div id="analysis-of-variance-anova-pooling" class="section level2">
<h2><span class="header-section-number">3.17</span> Analysis of Variance (ANOVA) pooling</h2>
<div id="analysis-of-variance-anova-pooling-in-spss" class="section level3">
<h3><span class="header-section-number">3.17.1</span> Analysis of Variance (ANOVA) pooling in SPSS</h3>
<p>The pooling of Analysis of Variance (ANOVA) statistics is not available in SPSS. In Figure <a href="single-missing-data-imputation.html#fig:tab5-7">3.49</a> the table is shown as a result of ANOVA after multiple imputation. It is clear from the Figure that the pooled results are lacking.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-7"></span>
<img src="images/table5.7.png" alt="ANOVA in SPSS without a pooled result." width="90%" />
<p class="caption">
Figure 3.49: ANOVA in SPSS without a pooled result.
</p>
</div>
</div>
<div id="analysis-of-variance-anova-pooling-in-r" class="section level3">
<h3><span class="header-section-number">3.17.2</span> Analysis of Variance (ANOVA) pooling in R</h3>
<p>The pooled ANOVA procedure uses the same function as was used in the previous paragraph to derive the pooled Chi-square value, because the Chi and the F-value are related. The easiest way to obtain a p-value for the ANOVA is by using the mi.anova function in the miceadds package. In this function a regression based formula can be defined to get a p-value.</p>
<p>To compare the Function means between three Tampascale variable groups, you use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the dataset</span>
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 Missing_Tampa_Cat.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate 5 impued datasets </span>
<span class="co"># and set printFlag = F for a silent imputation</span>
imp.Tampa.cat &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">5</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2345</span>, <span class="dt">printFlag =</span> F)

<span class="co"># Apply the mi.anova function</span>
<span class="kw">library</span>(miceadds)
<span class="kw">mi.anova</span>(<span class="dt">mi.res=</span>imp.Tampa.cat, <span class="dt">formula=</span><span class="st">&quot;Function ~ Tampa_Cat&quot;</span> )</code></pre></div>
<pre><code>## Univariate ANOVA for Multiply Imputed Data (Type 2)  
## 
## lm Formula:  Function ~ Tampa_Cat
## R^2=0.1494 
## ..........................................................................
## ANOVA Table 
##                   SSQ df1      df2 F value Pr(&gt;F)    eta2 partial.eta2
## Tampa_Cat    427.7156   1 100.1874 20.5678  2e-05 0.14943      0.14943
## Residual    2434.6298  NA       NA      NA     NA      NA           NA</code></pre>
<p>The pooled F and p-values are reported under the columns F value and Pr(&gt;F) respectively.</p>
</div>
</div>
<div id="pooling-regression-models" class="section level2">
<h2><span class="header-section-number">3.18</span> Pooling Regression models</h2>
<div id="pooling-linear-regression-models-in-spss" class="section level3">
<h3><span class="header-section-number">3.18.1</span> Pooling Linear Regression Models in SPSS</h3>
<p>To pool the results from a linear regression analysis RubinÂ´s Rules are used. To study the relationship between the Tampascale (independent) and Function (dependent) variables go to:</p>
<blockquote>
<p>Analyze -&gt; Regression -&gt; Linear.</p>
</blockquote>
<p>Transport the variable Function to the Dependent window and the Tampa scale variable to the Independent(s) window. To get pooled 95% Confidence Intervals, go to Statistics and select the Confidence Intervals option. Than click on Continue and OK.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-8"></span>
<img src="images/table5.8.png" alt="Relationship between Tampascale and Function estimated with linear regression in SPSS." width="90%" />
<p class="caption">
Figure 3.50: Relationship between Tampascale and Function estimated with linear regression in SPSS.
</p>
</div>
<p>Information is provided in the row called Pooled about the parameter estimates, i.e.Â regression coefficients, standard errors, t-values, p-values and confidence interval. Further, information is provided about the Fraction of Missing Information, Relative Increase Variance and Relative Efficiency.</p>
</div>
<div id="pooling-linear-regression-models-in-r" class="section level3">
<h3><span class="header-section-number">3.18.2</span> Pooling Linear regression models in R</h3>
<p>A pooled linear regression analyses can be produced by using the with and pool functions in the mice package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">3715</span>, <span class="dt">printFlag=</span>F)

fit &lt;-<span class="st"> </span><span class="kw">with</span>(<span class="dt">data=</span>imp,<span class="dt">exp=</span><span class="kw">lm</span>(Function <span class="op">~</span><span class="st"> </span>Tampascale))
lin.pool &lt;-<span class="st"> </span><span class="kw">pool</span>(fit)
<span class="kw">summary</span>(lin.pool)</code></pre></div>
<pre><code>##              estimate  std.error statistic       df     p.value
## (Intercept) 26.307730 3.51479517  7.484854 6.671497 0.000176412
## Tampascale  -0.375401 0.09252282 -4.057388 5.963136 0.005338392</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Results of the pooled procedure, with:</span>
<span class="co">#   est: Pooled regression coefficient.</span>
<span class="co">#   se: Standard error of pooled regression coefficient.</span>
<span class="co">#   t: T-value.</span>
<span class="co">#   df: Degrees of freedom.</span>
<span class="co">#   Pr(&gt;|t|): P-value.</span>
<span class="co">#   lo 95 and hi 95: 95% lower and upper confidence intervals.</span>
<span class="co">#   nmis: number of missing observations.</span>
<span class="co">#   fmi: fraction of missing information.</span>
<span class="co">#   Lambda: Proportion of the variation attributable to the missing data </span></code></pre></div>
</div>
<div id="pooling-logistic-regression-models-in-spss" class="section level3">
<h3><span class="header-section-number">3.18.3</span> Pooling Logistic Regression models in SPSS</h3>
<p>To study the relationship between the variables Function (independent variable) and Radiation in the Leg (dependent variable we need Logistic regression. This procedure can be done in SPSS via</p>
<blockquote>
<p>Analyze -&gt; Regression -&gt; Binary Logistic.</p>
</blockquote>
<p>Transport the variable Radiation in the Leg to the Dependent window and the Function variable to the Covariates window. To get pooled 95% Confidence Intervals, go to Options and select the CI for exp(B) option. Than click on Continue and OK.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-9"></span>
<img src="images/table5.9.png" alt="Logistic Regression in SPSS." width="90%" />
<p class="caption">
Figure 3.51: Logistic Regression in SPSS.
</p>
</div>
<p>information is provided in the row called Pooled about the parameter estimates, i.e.Â regression coefficients (B), standard errors (S.E.), p-values (Sig.), odds ratioÂ´s (Exp(B) and 95% confidence intervals around the OR (95% C.I. for EXP(B). Further, information is provided about the Fraction of Missing Information, Relative Increase Variance and Relative Efficiency. For the pooled coefficient and standard error RubinÂ´s Rules (RR) are used.</p>
</div>
<div id="pooling-logistic-regression-models-in-r" class="section level3">
<h3><span class="header-section-number">3.18.4</span> Pooling Logistic Regression models in R</h3>
<p>You can use mice to get pooled results after logistic regression. In combination with the pool function you have to use the following R code.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp.LR &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2268</span>, <span class="dt">printFlag =</span> <span class="ot">FALSE</span>)
fit &lt;-<span class="st"> </span><span class="kw">with</span>(<span class="dt">data=</span>imp.LR, <span class="dt">exp=</span><span class="kw">glm</span>(Radiation <span class="op">~</span><span class="st"> </span>Function, <span class="dt">family =</span> binomial))
<span class="kw">summary</span>(<span class="kw">pool</span>(fit))</code></pre></div>
<pre><code>##                estimate  std.error  statistic       df   p.value
## (Intercept)  0.33331305 0.54023681  0.6169758 30.48361 0.5418318
## Function    -0.06669438 0.04498345 -1.4826425 26.76133 0.1484349</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#   Results of the pooled procedure, with:</span>
<span class="co">#   est: Pooled regression coefficient.</span>
<span class="co">#   se: Standard error of pooled regression coefficient.</span>
<span class="co">#   t: T-value.</span>
<span class="co">#   df: Degrees of freedom.</span>
<span class="co">#   Pr(&gt;|t|): P-value.</span>
<span class="co">#   lo 95 and hi 95: 95% lower and upper confidence intervals.</span>
<span class="co">#   nmis: number of missing observations.</span>
<span class="co">#   fmi: fraction of missing information.</span>
<span class="co">#   Lambda: Proportion of the variation attributable to the missing data </span></code></pre></div>
<p>Under the Line with the R code summary(pool(fit)), the pooled estimates are provided. To extract the ORs and the corresponding 95% Confidence intervals you have to apply the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#summary.fit &lt;- summary(pool(fit))</span>
<span class="co">#pool.OR &lt;- exp(cbind(summary.fit[,1],summary.fit[,6],summary.fit[,7]))</span>
<span class="co">#colnames(pool.OR) &lt;- (c(&quot;OR&quot;, &quot;95% LO&quot;, &quot;95% UP&quot;))</span>
<span class="co">#pool.OR</span></code></pre></div>
<p>Another procedure to get the pooled estimates from a logistic regression model is by using the micombine function in the mitools package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mitools)
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">seed=</span><span class="dv">2268</span>, <span class="dt">printFlag =</span> F)
dataset1 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">1</span>)
dataset2 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">2</span>)
dataset3 &lt;-<span class="st"> </span><span class="kw">complete</span>(imp,<span class="dv">3</span>)
 
dataset.imp &lt;-<span class="st"> </span><span class="kw">list</span>(dataset1, dataset2, dataset3)
 
imp.LR &lt;-<span class="st"> </span><span class="kw">lapply</span>(dataset.imp, <span class="cf">function</span>(x) {
   <span class="kw">glm</span>(Radiation <span class="op">~</span><span class="st"> </span>Function, <span class="dt">family =</span> binomial, <span class="dt">data =</span> x)
  })
coef &lt;-<span class="st"> </span><span class="kw">MIextract</span>(imp.LR, <span class="dt">fun=</span>coef) 
se &lt;-<span class="st"> </span><span class="kw">MIextract</span>(imp.LR, <span class="dt">fun=</span>vcov) 
 
summary.fit &lt;-<span class="st"> </span><span class="kw">summary</span>(<span class="kw">MIcombine</span>(coef, se) )</code></pre></div>
<pre><code>## Multiple imputation results:
##       MIcombine.default(coef, se)
##                 results         se     (lower     upper) missInfo
## (Intercept)  0.33331305 0.54023681 -0.7572339 1.42385997     25 %
## Function    -0.06669438 0.04498345 -0.1579936 0.02460484     28 %</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pool.OR &lt;-<span class="st"> </span><span class="kw">exp</span>(summary.fit[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">5</span>)]) 
<span class="kw">colnames</span>(pool.OR) &lt;-<span class="st"> </span>(<span class="kw">c</span>(<span class="st">&quot;OR&quot;</span>, <span class="st">&quot;95% LO&quot;</span>, <span class="st">&quot;95% UP&quot;</span>))
pool.OR</code></pre></div>
<pre><code>##                    OR    95% LO  95% UP
## (Intercept) 1.3955841 0.4689618 4.15312
## Function    0.9354811 0.8538552 1.02491</code></pre>
<p>However, the pooled p-value is still missing. You can get the pooled p-values from the mi.inference function in the NORM package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(norm)
se &lt;-<span class="st"> </span><span class="kw">lapply</span>(se, <span class="cf">function</span>(x) <span class="kw">sqrt</span>(<span class="kw">diag</span>(x)) )
 
res &lt;-<span class="st"> </span><span class="kw">mi.inference</span>(coef,se)
res.pool &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">unlist</span>(res), <span class="dv">2</span>, <span class="dv">8</span>, <span class="dt">byrow=</span>F)
<span class="kw">colnames</span>(res.pool) &lt;-<span class="st"> </span><span class="kw">names</span>(res)
<span class="kw">rownames</span>(res.pool) &lt;-<span class="st"> </span><span class="kw">names</span>(res<span class="op">$</span>est)
res.pool</code></pre></div>
<pre><code>##                     est    std.err       df    signif      lower
## (Intercept)  0.33331305 0.54023681 41.60735 0.5406124 -0.7572339
## Function    -0.06669438 0.04498345 35.23806 0.1470584 -0.1579936
##                  upper         r     fminf
## (Intercept) 1.42385997 0.2808117 0.2542508
## Function    0.02460484 0.3127440 0.2780801</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pool.OR &lt;-<span class="st"> </span><span class="kw">exp</span>(res.pool[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">8</span>)]) 
<span class="kw">colnames</span>(pool.OR) &lt;-<span class="st"> </span>(<span class="kw">c</span>(<span class="st">&quot;OR&quot;</span>, <span class="st">&quot;95% LO&quot;</span>, <span class="st">&quot;95% UP&quot;</span>))
pool.OR</code></pre></div>
<pre><code>##                    OR    95% LO  95% UP
## (Intercept) 1.3955841 0.4689618 4.15312
## Function    0.9354811 0.8538552 1.02491</code></pre>
<p>The p-value in the NORM package is equal to the p-value in SPSS. This means that the NORM package also uses the older method to calculate the degrees of freedom.</p>
</div>
</div>
<div id="pooling-logistic-regression-models-including-categorical-independent-variables" class="section level2">
<h2><span class="header-section-number">3.19</span> Pooling logistic regression models including categorical independent variables</h2>
<p>For categorical variables in logistic regression models, different methods are available to test the variable as a whole for significance. These so called Multiparameter tests are not available in SPSS, but they are available in R. These tests will be discussed in the next Chapter. We will start with an example of univariate pooling in SPSS.</p>
<div id="pooling-cox-regression-models" class="section level3">
<h3><span class="header-section-number">3.19.1</span> Pooling Cox regression models</h3>
<p>One of the most used statistical models for survival data is the Cox regression model. With survival data you have two outcome measures, the status variable and the time to event variable. As a guideline, all variables of the main analysis, including the outcome variable have to be part of the imputation model. The best way to include the outcome variable in a Cox regression model is not by using the Time variable itself, but by using the cumulative hazard to the survival time. This value has to be included in the imputation model together with the status variable and the auxiliary variables.</p>
</div>
<div id="pooling-cox-regression-models-in-spss" class="section level3">
<h3><span class="header-section-number">3.19.2</span> Pooling Cox regression models in SPSS</h3>
<p>The cumulative hazard value can easily be calculated in SPSS by using the Survival menu and then choose for</p>
<blockquote>
<p>Analyze -&gt; Cox Regression</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:fig5-5"></span>
<img src="images/fig5.5.png" alt="The survival options in SPSS." width="90%" />
<p class="caption">
Figure 3.52: The survival options in SPSS.
</p>
</div>
<p>Than choose for Save and the following window will open.</p>
<div class="figure" style="text-align: center"><span id="fig:fig5-6"></span>
<img src="images/fig5.6.png" alt="The Save menu under Cox regression." width="90%" />
<p class="caption">
Figure 3.53: The Save menu under Cox regression.
</p>
</div>
<p>Here you can choose for Hazard function. Then click on Continue and OK. A new variable will we added to the dataset, which is called HZA_1. This cumulative hazard variable can be included in the imputation model to impute missing data in the Pain variable.</p>
<p>The pooling of the Cox regression model will be done in the datasets that are imputed in R. Than we can compare the output from the pooled model in SPSS and in R.</p>
<p>To get pooled results of Cox regression models you use:</p>
<blockquote>
<p>Analyze -&gt; Survival -&gt; Cox Regression</p>
</blockquote>
<p>Transport the survival time variable to Time window, the event variable to the Status window and the independent variable Pain to the Covariates window. To get pooled 95% Confidence Intervals, go to Options and select the CI for exp(B) option. Than click on Continue and OK.</p>
<div class="figure" style="text-align: center"><span id="fig:tab5-10"></span>
<img src="images/table5.10.png" alt="The pooled Cox regression model estimated in SPSS." width="90%" />
<p class="caption">
Figure 3.54: The pooled Cox regression model estimated in SPSS.
</p>
</div>
<p>This procedure provides a pooled value for the regression coefficient, standard error, p-value (of 0.000589), hazard ratio and related 95% confidence intervals and provides information about the fraction of missing information, the relative increase in variance and the relative efficiency.</p>
<div id="pooling-cox-regression-models-in-r" class="section level4">
<h4><span class="header-section-number">3.19.2.1</span> Pooling Cox regression models in R</h4>
<p>For this procedure we can make use of the pool function that is available in the mice package.</p>
<p>We start by using the mice function to impute missing data in the Pain variable by first calculating the cumulative hazard values. After that we customize the predictorMatrix so that the Time variable is not used to predict the missing values (we use the cumulative hazard function instead) in the Pain variable and subsequently the imputed datasets will be pooled to get a summary estimate. Note that you also have to activate the package survival before you can run the coxph function in R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the dataset</span>
<span class="kw">library</span>(survival)
dataset &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file=</span><span class="st">&quot;Backpain 150 Survival Missing.sav&quot;</span>, <span class="dt">to.data.frame=</span>T)</code></pre></div>
<pre><code>## re-encoding from UTF-8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Compute the cumulative hazard, attach it to the dataset</span>
<span class="co"># and omit the ID variable (first column)</span>
Hazard &lt;-<span class="st"> </span><span class="kw">nelsonaalen</span>(dataset, Time, Status)
dataset &lt;-<span class="st"> </span><span class="kw">data.frame</span>(dataset, Hazard)

<span class="co"># Adapt the PredictorMatrix so that the</span>
<span class="co"># Time variable is not included in the imputation model</span>
Cox.imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">1</span>, <span class="dt">maxit=</span><span class="dv">0</span>, <span class="dt">seed=</span><span class="dv">2795</span>, <span class="dt">printFlag=</span>F)
Pred &lt;-<span class="st"> </span>Cox.imp<span class="op">$</span>predictorMatrix
Pred[<span class="dv">2</span>, <span class="st">&quot;Time&quot;</span>] &lt;-<span class="st"> </span><span class="dv">0</span>
Pred</code></pre></div>
<pre><code>##            Time Status Pain Tampascale Function Radiation Hazard
## Time          0      1    1          1        1         1      1
## Status        0      0    1          1        1         1      1
## Pain          1      1    0          1        1         1      1
## Tampascale    1      1    1          0        1         1      1
## Function      1      1    1          1        0         1      1
## Radiation     1      1    1          1        1         0      1
## Hazard        1      1    1          1        1         1      0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Start imputations using mice</span>
Cox.imp &lt;-<span class="st"> </span><span class="kw">mice</span>(dataset, <span class="dt">m=</span><span class="dv">3</span>, <span class="dt">maxit=</span><span class="dv">50</span>, <span class="dt">predictorMatrix=</span>Pred, <span class="dt">seed=</span><span class="dv">2795</span>, <span class="dt">printFlag=</span>F)

fit.Cox &lt;-<span class="st"> </span><span class="kw">with</span>(<span class="dt">data=</span>Cox.imp, <span class="dt">exp=</span><span class="kw">coxph</span>(<span class="kw">Surv</span>(Time, Status) <span class="op">~</span><span class="st"> </span>Pain))
Cox.pool &lt;-<span class="st"> </span><span class="kw">pool</span>(fit.Cox)</code></pre></div>
<pre><code>## Warning: Unknown or uninitialised column: &#39;df.residual&#39;.</code></pre>
<pre><code>## Warning in pool.fitlist(getfit(object), dfcom = dfcom): Large sample
## assumed.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(Cox.pool)</code></pre></div>
<pre><code>##        estimate  std.error statistic       df      p.value
## Pain -0.2021694 0.04789423 -4.221165 36823.71 2.436252e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#   Results of the pooled procedure, with:</span>
<span class="co">#   est: Pooled regression coefficient.</span>
<span class="co">#   se: Standard error of pooled regression coefficient.</span>
<span class="co">#   t: T-value.</span>
<span class="co">#   df: Degrees of freedom.</span>
<span class="co">#   Pr(&gt;|t|): P-value.</span>
<span class="co">#   lo 95 and hi 95: 95% lower and upper confidence intervals.</span>
<span class="co">#   nmis: number of missing observations.</span>
<span class="co">#   fmi: fraction of missing information.</span>
<span class="co">#   Lambda: Proportion of the variation attributable to the missing data </span></code></pre></div>
<p>The value of 0.3319019 in the column named fmi for the Pain variable is calculated according to the Formula 5.17 for FMI. The value 0.2811114 under the column named lambda is calculated according to Formula 5.13.</p>

</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Eekhout2012">
<p>Eekhout, I., R. M. de Boer, J. W. Twisk, H. C. de Vet, and M. W. Heymans. 2012. â€œMissing data: a systematic review of how they are reported and handled.â€ <em>Epidemiology</em> 23 (5): 729â€“32.</p>
</div>
<div id="ref-Eekhout2014">
<p>Eekhout, I., H. C. de Vet, J. W. Twisk, J. P. Brand, M. R. de Boer, and M. W. Heymans. 2014. â€œMissing data in a multi-item instrument were best handled by multiple imputation at the item score level.â€ <em>J Clin Epidemiol</em> 67 (3): 335â€“42.</p>
</div>
<div id="ref-VanBuuren2018">
<p>Van Buuren, S. 2018. <em>Flexible Imputation of Missing Data. Second Edition</em>. Boca Raton, FL: Chapman &amp; Hall/CRC.</p>
</div>
<div id="ref-enders2010applied">
<p>Enders, Craig K. 2010. <em>Applied Missing Data Analysis</em>. Guilford Press.</p>
</div>
<div id="ref-hippel2004">
<p>Hippel, P.T. von. 2004. â€œBiases in SPSS 12.0 Missing Values Analysis.â€ <em>The American Statistician</em> 58 (2): 160â€“64.</p>
</div>
<div id="ref-box2007bayesianinferencein">
<p>Box, G. E. P., and G. C. Tiao. 2007. <em>Bayesian Inference in Statistical Analysis</em>. Addison-Wesley Publishing Company.</p>
</div>
<div id="ref-gelman2014bayesian">
<p>Gelman, Andrew, John B Carlin, Hal S Stern, and Donald B Rubin. 2014. <em>Bayesian Data Analysis</em>. Vol. 2. Taylor; Francis.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="missing-data-evaluation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="more-topics-on-multiple-imputation-and-regression-modelling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
